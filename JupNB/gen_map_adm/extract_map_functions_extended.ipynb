{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Code\\\\ditto_v2'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PATH\n",
    "import os\n",
    "os.chdir('/Code/ditto_v2')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset  # clean all variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.INPUTS (`d_inputs`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reset  # clean all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### `d_inputs` INPUTS DICTIONARY ###\n",
    "d_inputs = {\n",
    "    'gadm' : 'D2',\n",
    "    'l_country_data' : [\n",
    "        # 'D1', 'D2','D3', 'D4', 'ZIP', \n",
    "        'census'\n",
    "        ],\n",
    "    'radius_km' : 20,\n",
    "# ['Bayern','Baden-Württemberg','Hessen','Nordrhein-Westfalen','Rheinland-Pfalz', \\\n",
    "#             'Saarland','Sachsen','Sachsen-Anhalt','Thüringen','Berlin','Brandenburg','Mecklenburg-Vorpommern', \\\n",
    "#                 'Hamburg','Niedersachsen','Schleswig-Holstein','Bremen']\n",
    "    'l_regions' : ['Bayern','Baden-Württemberg'],\n",
    "    # 'l_regions' : ['Hessen', 'Baden-Württemberg'],\n",
    "    # 'l_regions' : ['Hessen', 'Rheinland-Pfalz'],\n",
    "    # 'l_regions' : ['Baden-Württemberg'],\n",
    "    # 'l_regions' : ['Bayern'],\n",
    "    # 'l_regions' : ['Hessen'],\n",
    "\n",
    "    # 'l_stores' : ['sportscheck'],\n",
    "    # 'l_stores' : ['decathlon'],\n",
    "    # 'l_stores' : ['decathlon', 'sportscheck'],\n",
    "    'l_stores' : ['sportscheck', 'decathlon','intersport'],\n",
    "\n",
    "    'stores' : { # d_stores\n",
    "        'sportscheck' : {\n",
    "            'color' : 'orange'\n",
    "        },\n",
    "        'decathlon' : {\n",
    "            'color' : (0.0, 130.0, 195.0, 255.0) # 'darkblue' # \n",
    "        },\n",
    "        'intersport' : {\n",
    "            'color' : 'darkred'\n",
    "        }\n",
    "    },\n",
    "    'merged_stores' : {\n",
    "        'color' : 'yellow',\n",
    "    },\n",
    "    ### 3.1. d_roi (Towns, Stores, Circles)\n",
    "    'maps_roi' : { # d_roi\n",
    "        'maps_roi_is_roi' :        True,\n",
    "        'maps_roi_is_towns' :      True,\n",
    "        'maps_roi_is_stores' :     True,\n",
    "        'maps_roi_is_circles' :    False,\n",
    "    },\n",
    "    ### 3.2. d_poi (Mountains, Campings, Climbings)\n",
    "    'maps_poi' : { # d_roi\n",
    "        'mountains' : {\n",
    "            'map'     : True,\n",
    "            'clusters' : True,\n",
    "            'circles' : False\n",
    "        },\n",
    "        'campings'  : True,\n",
    "        'cluster_campings'  : True,\n",
    "        # 'circles_campings'  : True,\n",
    "\n",
    "        'climbings' : True,        \n",
    "        'cluster_climbings' : True,\n",
    "        # 'circles_climbings' : True,\n",
    "    },\n",
    "    'mountains' : {\n",
    "        'min_elev' : 1000.0,\n",
    "    },\n",
    "    'campings' : {\n",
    "        'min_capacity' : 20\n",
    "    },\n",
    "    # 'climbings' : {\n",
    "    #     'min_capacity' : 20\n",
    "    # },\n",
    "    ### 3.3. d_stores (Mountains, Campings, Climbings)\n",
    "    'maps_stores' : { # d_stores\n",
    "        'maps_stores_is_stores' :               True,\n",
    "        'maps_stores_is_pois' :                 True,\n",
    "        'maps_stores_is_circles' :              True,\n",
    "        'maps_stores_is_join' :                 False,\n",
    "        'maps_stores_is_intersection' :         False,\n",
    "        'maps_stores_is_merge' :                False,  # Can NOT be computed if maps_stores_is_merge False\n",
    "        'maps_stores_is_union_intersection':    False,  # Can NOT be computed if maps_stores_is_merge False\n",
    "        'maps_stores_is_union_merge':           True,  # Can NOT be computed if maps_stores_is_intersection False\n",
    "\n",
    "        'maps_stores_is_markers_inside':        False,\n",
    "        'maps_stores_is_markers_partly':        False,\n",
    "        'maps_stores_is_markers_outside':       False,\n",
    "    },\n",
    "    'is_logging' :              True,\n",
    "    'round_dec' :               3,\n",
    "    'is_simplified' :           False,\n",
    "    'simplification_tolerance' : 0.1,       #(0.01 unit in projected CRS means 0.01 unit in reality),\n",
    "\n",
    "    'path_census_D2' : './assets/Geo/Germany/D1_Deutschland_census.json',\n",
    "\n",
    "}\n",
    "\n",
    "### LISTS ###\n",
    "l_stores= d_inputs['l_stores']\n",
    "l_states = d_inputs['l_regions']\n",
    "l_country_data = d_inputs['l_country_data']\n",
    "\n",
    "### STRINGS ###\n",
    "gadm = d_inputs['gadm']\n",
    "path_census_D2 = d_inputs['path_census_D2']\n",
    "\n",
    "### FLOATS ###\n",
    "simplification_tolerance = float(d_inputs['simplification_tolerance'])\n",
    "\n",
    "### INTS ###\n",
    "round_dec = int(d_inputs['round_dec'])\n",
    "radius_km = int(d_inputs['radius_km'])\n",
    "\n",
    "### BOOLS ###\n",
    "is_logging =    d_inputs['is_logging']\n",
    "is_simplified = d_inputs['is_simplified']\n",
    "\n",
    "### d_roi ('maps_roi')###\n",
    "maps_roi_is_roi     = d_inputs['maps_roi']['maps_roi_is_roi']\n",
    "maps_roi_is_towns   = d_inputs['maps_roi']['maps_roi_is_towns']\n",
    "maps_roi_is_stores  = d_inputs['maps_roi']['maps_roi_is_stores']\n",
    "maps_roi_is_circles = d_inputs['maps_roi']['maps_roi_is_circles']\n",
    "\n",
    "### d_poi ('maps_poi')###\n",
    "maps_poi_mountains  = d_inputs['maps_poi']['mountains']['map']\n",
    "maps_poi_mountains_clusters  = d_inputs['maps_poi']['mountains']['clusters']\n",
    "maps_poi_mountains_circles  = d_inputs['maps_poi']['mountains']['circles']\n",
    "mountains_min_elev = d_inputs['mountains']['min_elev']\n",
    "\n",
    "maps_poi_campings   = d_inputs['maps_poi']['campings']\n",
    "maps_poi_cluster_campings   = d_inputs['maps_poi']['cluster_campings']\n",
    "# maps_poi_circles_campings   = d_inputs['maps_poi']['circles_campings']\n",
    "campings_min_capacity = d_inputs['campings']['min_capacity']\n",
    "\n",
    "maps_poi_climbings  = d_inputs['maps_poi']['climbings']\n",
    "maps_poi_cluster_climbings  = d_inputs['maps_poi']['cluster_climbings']\n",
    "# maps_poi_circles_climbings  = d_inputs['maps_poi']['circles_climbings']\n",
    "\n",
    "\n",
    "### d_stores ('maps_stores')###\n",
    "maps_stores_is_stores             = d_inputs['maps_stores']['maps_stores_is_stores']\n",
    "maps_stores_is_pois               = d_inputs['maps_stores']['maps_stores_is_pois']\n",
    "maps_stores_is_circles            = d_inputs['maps_stores']['maps_stores_is_circles']\n",
    "maps_stores_is_join               = d_inputs['maps_stores']['maps_stores_is_join']\n",
    "maps_stores_is_intersection       = d_inputs['maps_stores']['maps_stores_is_intersection']\n",
    "maps_stores_is_merge              = d_inputs['maps_stores']['maps_stores_is_merge']\n",
    "maps_stores_is_union_intersection = d_inputs['maps_stores']['maps_stores_is_union_intersection']\n",
    "maps_stores_is_union_merge        = d_inputs['maps_stores']['maps_stores_is_union_merge']\n",
    "maps_stores_is_markers_inside     = d_inputs['maps_stores']['maps_stores_is_markers_inside']\n",
    "maps_stores_is_markers_partly     = d_inputs['maps_stores']['maps_stores_is_markers_partly']\n",
    "maps_stores_is_markers_outside    = d_inputs['maps_stores']['maps_stores_is_markers_outside']\n",
    "\n",
    "### d_roi ###\n",
    "merged_stores_color = d_inputs['merged_stores']['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.INGESTION (`gdf_census`, `gdf_stores`, `gdf_circles`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region of Interest(RoI): ['Bayern', 'Baden-Württemberg']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### l_bundeslaender ###\n",
    "from shapely import wkt\n",
    "from src.functionality_maps import Defs\n",
    "\n",
    "l_bundeslaender = [Defs.dict_bundeslaender_id[x] for x in l_states]\n",
    "print(f'Region of Interest(RoI): {l_states}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Census is loaded!\n",
      " Normalizing non-serializable columns... ['BEGINN', 'WSK']\n",
      " Columns ['BEGINN', 'WSK'] removed\n",
      "CENSUS/TOTAL: [10990]\n",
      " CENSUS inside RoI: [3332]\n"
     ]
    }
   ],
   "source": [
    "### gdf_census  ###\n",
    "from src.functionality_maps import f_maps, Defs\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "d_ger = f_maps.load_germany(l_levels=l_country_data, is_logging=is_logging)\n",
    "gdf_census = d_ger['census']                                        #### FILTERING CENSUS #####\n",
    "print(f'CENSUS/TOTAL: [{gdf_census.shape[0]}]')\n",
    "gdf_census = gdf_census[gdf_census['SN_L'].isin(l_bundeslaender)]   #### FILTERING CENSUS TO RoI ####\n",
    "print(f' CENSUS inside RoI: [{gdf_census.shape[0]}]')\n",
    "gdf_census = f_maps.enrich_census(gdf_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grouping geometries...\n",
      " Adding areas and renaming columns...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bundesland</th>\n",
       "      <th>EWZ</th>\n",
       "      <th>area_dbms</th>\n",
       "      <th>area_geom</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Baden-Württemberg</td>\n",
       "      <td>11280257</td>\n",
       "      <td>35219</td>\n",
       "      <td>35748.88</td>\n",
       "      <td>MULTIPOLYGON (((7.71191 47.5388, 7.71067 47.53...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bayern</td>\n",
       "      <td>13369393</td>\n",
       "      <td>69430</td>\n",
       "      <td>70544.94</td>\n",
       "      <td>POLYGON ((9.6502 47.55793, 9.6492 47.55843, 9....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Bundesland       EWZ  area_dbms  area_geom  \\\n",
       "7  Baden-Württemberg  11280257      35219   35748.88   \n",
       "8             Bayern  13369393      69430   70544.94   \n",
       "\n",
       "                                            geometry  \n",
       "7  MULTIPOLYGON (((7.71191 47.5388, 7.71067 47.53...  \n",
       "8  POLYGON ((9.6502 47.55793, 9.6492 47.55843, 9....  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### gdf_cm, gdf_census_merged ###\n",
    "import geopandas as gpd\n",
    "path_census_D2 = './assets/Geo/Germany/D1_Deutschland_census.json'\n",
    "gdf_census_merged = gpd.read_file(path_census_D2)\n",
    "# gdf_census_merged = f_maps.merge_census_geom(d_ger['census'], is_logging=is_logging)\n",
    "# gdf_census_merged.to_file(path_census_D2)\n",
    "\n",
    "## FILTER DATA BY l_statesbb\n",
    "\n",
    "gdf_census_merged = gdf_census_merged[gdf_census_merged['Bundesland'].isin(l_states)]\n",
    "gdf_census_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stores...\n",
      "STORES/TOTAL = 508\n",
      " STORES/Valid coords = 500\n",
      " STORES/Selected [['sportscheck', 'decathlon', 'intersport']]= 500\n",
      " CIRCLES/Total = 500\n",
      " CIRCLES/RoI = 168\n",
      " STORES/RoI+SoI = 168\n"
     ]
    }
   ],
   "source": [
    "### gdf_stores, gdf_circles ###\n",
    "from src.functionality_maps import paths\n",
    "import geopandas as gpd\n",
    "\n",
    "### PDF_STORES ###\n",
    "print('Loading stores...')\n",
    "pdf_stores = pd.read_json(paths.stores, orient='records', lines=True)\n",
    "pdf_stores['store_name'] = pdf_stores[\"store\"] +\"_\" +  pdf_stores[\"name\"]   ## ADD NAME OF STORE\n",
    "print(f'STORES/TOTAL = {pdf_stores.shape[0]}')\n",
    "pdf_stores = pdf_stores.dropna(subset=['lat','lon'])                        ### FILTER STORES WITH NO COORDS ###\n",
    "print(f' STORES/Valid coords = {pdf_stores.shape[0]}')\n",
    "pdf_stores = pdf_stores[pdf_stores['store'].isin(l_stores)]                 ### FILTER STORES WITH IN l_stores ###\n",
    "print(f' STORES/Selected [{l_stores}]= {pdf_stores.shape[0]}')\n",
    "pdf_stores['geometry'] = pdf_stores['point'].apply(wkt.loads)                  ### CONVERTING POINT COL TO GEOM ###\n",
    "gdf_stores = gpd.GeoDataFrame(pdf_stores).set_geometry('geometry')\n",
    "gdf_stores = gdf_stores.set_crs(4326)\n",
    "\n",
    "#### gdf_circles ##### (VERY INEFFICIENT CODE)\n",
    "## GENERATING CIRCLES AROUND STORES ##\n",
    "gdf_circles_allstores = f_maps.get_gdf_circle(df=pdf_stores[['lon','lat','store','store_name','name', 'address']], radius_km= radius_km)\n",
    "l_stores_all = gdf_circles_allstores['store_name'].drop_duplicates().to_list()\n",
    "print(f' CIRCLES/Total = {len(l_stores_all)}')\n",
    "\n",
    "#### gdf_circles #####\n",
    "### JOIN CENSUS WITH CIRCLES ###\n",
    "gdf_circles = gpd.sjoin(gdf_circles_allstores.to_crs(4326), gdf_census[['geometry']].to_crs(epsg=4326), \n",
    "                        how=\"inner\", predicate=\"intersects\")\n",
    "gdf_circles = gdf_circles.drop(['index_right'], axis=1).drop_duplicates()\n",
    "l_stores_roi = gdf_circles['store_name'].drop_duplicates().to_list()\n",
    "print(f' CIRCLES/RoI = {len(l_stores_roi)}')\n",
    "\n",
    "gdf_stores = gdf_stores[gdf_stores['store_name'].isin(l_stores_roi)]\n",
    "print(f' STORES/RoI+SoI = {gdf_stores.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTATION `OpenStreetMap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install overpass\n",
    "# %pip install overpy\n",
    "# import overpy\n",
    "# api = overpy.Overpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXAMPLE - fetch all ways and nodes\n",
    "# result = api.query(\"\"\"\n",
    "#     way(50.746,7.154,50.748,7.157) [\"highway\"];\n",
    "#     (._;>;);\n",
    "#     out body;\n",
    "#     \"\"\")\n",
    "\n",
    "\n",
    "# for way in result.ways:\n",
    "#     print(\"Name: %s\" % way.tags.get(\"name\", \"n/a\"))\n",
    "#     print(\"  Highway: %s\" % way.tags.get(\"highway\", \"n/a\"))\n",
    "#     print(\"  Nodes:\")\n",
    "#     for node in way.nodes:\n",
    "#         print(\"    Lat: %f, Lon: %f\" % (node.lat, node.lon))\n",
    "\n",
    "\n",
    "# # fetch all ways and nodes\n",
    "# result = api.query(\"\"\"\n",
    "#     way(50.746,7.154,50.748,7.157) [\"highway\"];\n",
    "#     (._;>;);\n",
    "#     out body;\n",
    "#     \"\"\")\n",
    "\n",
    "# for way in result.ways:\n",
    "#     print(f\"Name: {way.tags.get('name', 'n/a')}\")\n",
    "#     print(f\"  Highway: {way.tags.get('highway', 'n/a')}\")\n",
    "#     print(\"  Nodes:\")\n",
    "#     for node in way.nodes:\n",
    "#         print(f\"    Lat: {node.lat:f}, Lon: {node.lon:f}\")\n",
    "\n",
    "# result = api.query(\"\"\"\n",
    "#     area[name=\"Frankfurt am Main\"];\n",
    "#     way(area)[highway][name];\n",
    "#     out;\n",
    "#     \"\"\")\n",
    "# result.ways[0].tags#.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import overpy\n",
    "# api = overpy.Overpass()\n",
    "# # fetch all  nodes\n",
    "# result = api.query(\"\"\"\n",
    "#     node[\"natural\"=\"peak\"](47.53236,7.511872,49.791478,10.495749);\n",
    "#     out meta;\n",
    "#     \"\"\")\n",
    "# result\n",
    "\n",
    "# # fetch all ways and nodes\n",
    "# result = api.query(\"\"\"\n",
    "#     node(47.53236,7.511872,49.791478,10.495749)[natural=peak];\n",
    "#     out meta;\n",
    "#     \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_res = pd.DataFrame(res, columns=['nodes'])\n",
    "# pdf_res['lat'] = pdf_res.nodes.apply(lambda x: x.lat)\n",
    "# pdf_res['lon'] = pdf_res.nodes.apply(lambda x: x.lon)\n",
    "# pdf_res['tags'] = pdf_res.nodes.apply(lambda x: x.tags)\n",
    "\n",
    "# l_keys_to_extract = ['name','ele']\n",
    "# l_values_default = ['', 'nan']\n",
    "\n",
    "# for key,default_value in zip(l_keys_to_extract,l_values_default):\n",
    "#     pdf_res[key] = pdf_res.tags.apply(lambda x: x[key] if key in list(x.keys()) else default_value)\n",
    "\n",
    "\n",
    "# pdf_res['ele'] = pdf_res['ele'].str.replace(',','.')\n",
    "# # pdf_res['ele'] = pdf_res.tags.apply(lambda x: {} if 'ele' in list(x.keys()) else x.ele)\n",
    "# # pdf_res['name'] = pdf_res.tags.apply(lambda x: x['name'] if 'name' in list(x.keys()) else {})\n",
    "# pdf_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SIMPLIFY DATA GEOMETRIES (TO MAKE PROCESSIN GASTER)\n",
    "# if is_simplified:\n",
    "#     gdf_census['geometry'] = gdf_census.geometry.simplify(simplification_tolerance)\n",
    "#     gdf_census_merged['geometry'] = gdf_census_merged.geometry.simplify(simplification_tolerance)\n",
    "\n",
    "# gdf_census_simp.info()\n",
    "# gdf_census_merged.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.FUNCTIONS TO EXTRACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "import folium\n",
    "\n",
    "def pairwise_min_dist(gdf1:gpd.GeoDataFrame, gdf2:gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "    gdf1['coords'] = gdf1.apply(lambda x: (x['lat'], x['lon']), axis=1)\n",
    "    gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n",
    "\n",
    "    coords_list1 = gdf1.coords.to_list()\n",
    "    l_store_name = gdf1.store_name.to_list()\n",
    "    coords_list2 = gdf2.coords.to_list()\n",
    "    l_ARS_city = gdf2.ARS.to_list()\n",
    "    l_city = gdf2.GEN.to_list()\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    d_dist = {}\n",
    "    for i,(coord2,ARS,city) in enumerate(zip(coords_list2,l_ARS_city,l_city)):\n",
    "        distances = []\n",
    "        for j,(coord1,store_name) in enumerate(zip(coords_list1,l_store_name)):\n",
    "            # print(f'j={j+1}, city={city}')\n",
    "            distance = geodesic(coord1, coord2).km\n",
    "            distances.append(distance)\n",
    "            \n",
    "        d_dist[ARS] = {\n",
    "            'GEN' : city,\n",
    "            'dist' : distances,\n",
    "            'store' : l_store_name,\n",
    "            'latlon_store': coords_list2,\n",
    "            'latlon_gen' : coords_list1\n",
    "        }\n",
    "        \n",
    "    pdf_dist = pd.DataFrame.from_dict(d_dist, orient='index')\n",
    "    pdf_dist2 = pdf_dist.explode(['dist', 'store']).reset_index(names=['ARS'])\n",
    "\n",
    "    indices = pdf_dist2.groupby(['ARS','GEN'])['dist'].idxmin()\n",
    "    pdf_dist2.loc[indices,'dist_min_store'] = pdf_dist2.loc[indices, 'store']\n",
    "    pdf_dist2= pdf_dist2[pdf_dist2['dist_min_store'].notna()]\n",
    "    return pdf_dist2\n",
    "\n",
    "def get_fg_markers_region(gdf:gpd.GeoDataFrame, position:str, color:str, round_dec:int,\n",
    "                            l_tooltip:list=['GEN', 'dist'], col_lat:str='lat', col_lon:str='lon',\n",
    "                            is_shown:bool=False, is_logging:bool=False) -> folium.FeatureGroup:\n",
    "    num_towns = gdf.shape[0]\n",
    "    markers = f_maps.get_markers_polygon(gdf,\n",
    "                                            l_tooltip=l_tooltip, \n",
    "                                            col_lat=col_lat, col_lon=col_lon, \n",
    "                                            name=f'Markers {position} [{num_towns}]', \n",
    "                                            color=color)\n",
    "    pop_total = round(gdf.EWZ.sum()/10**6,round_dec)\n",
    "    pop_inside = 0\n",
    "    if position in ['inside', 'partly']:\n",
    "        pop_inside = round(gdf.EWZ_int.sum()/10**6,round_dec)\n",
    "    avg_geom_int = 0\n",
    "    if position in ['inside', 'partly']:\n",
    "        avg_geom_int = round(100*gdf.PERC_geom_int.mean(), round_dec)\n",
    "    fg = folium.FeatureGroup(name=f'Markers - {position} [towns:{num_towns}, \\\n",
    "                                    Pop_inside:{pop_inside}M/Pop_partly:{pop_total}M/Avg perc={avg_geom_int}%]',\n",
    "                                    show = is_shown)\n",
    "    markers.add_to(fg)\n",
    "    return fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gdf_all_stores(df:gpd.GeoDataFrame, gdf_census:gpd.GeoDataFrame, \n",
    "                       l_groupby:list=['BL','store'], round_dec:int=3) -> [gpd.GeoDataFrame, gpd.GeoDataFrame]:\n",
    "    poly_merged_allstores = df.geometry.union_all()\n",
    "    gdf_merged_allstores = gpd.GeoSeries([poly_merged_allstores]).to_frame(name='geometry').set_crs(epsg=6933)\n",
    "\n",
    "    gdf_merged_allstores = df.groupby(l_groupby).agg( \\\n",
    "            {'geometry': lambda x: x.geometry.union_all(),\n",
    "            'num_stores':'sum', \n",
    "            }).set_geometry(\"geometry\").set_crs(6933).reset_index()\n",
    "\n",
    "    gdf_census_region = gdf_census.to_crs(6933)\n",
    "    gdf_union_int_allstores = gpd.overlay(gdf_census_region, gdf_merged_allstores.to_crs(6933), how='intersection')\n",
    "\n",
    "    Pop_sum = round(gdf_union_int_allstores.EWZ.sum()  / 10**6, round_dec)\n",
    "    gdf_merged_allstores['EWZ'] = Pop_sum\n",
    "    gdf_merged_allstores['area'] = round(gdf_merged_allstores.geometry.area.sum()/10**6, round_dec)\n",
    "    gdf_merged_allstores['perc_area'] = round(100*gdf_merged_allstores['area'] / fg_geom_area, round_dec)\n",
    "    gdf_merged_allstores['perc_pop'] = round((100*Pop_sum/10**6) / fg_geom_pop, round_dec)\n",
    "\n",
    "    return [gdf_union_int_allstores, gdf_merged_allstores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pdf_osm(lat_min, lon_min, lat_max, lon_max, args,\n",
    "                        l_keys_to_extract = [],\n",
    "                        l_values_default = [],\n",
    "                        d_key_replace = {},\n",
    "                        d_parse_types = {},\n",
    "                        l_drop_na = [],\n",
    "                        is_gdf: bool = True) -> pd.DataFrame:\n",
    "    import overpy\n",
    "    from shapely import geometry\n",
    "    \n",
    "    api = overpy.Overpass()\n",
    "    # fetch all  nodes\n",
    "    result = api.query(f\"\"\"\n",
    "        node[{args}]({lat_min},{lon_min},{lat_max},{lon_max});\n",
    "        out meta;\n",
    "        \"\"\")\n",
    "    pdf = pd.DataFrame(result.nodes, columns=['nodes'])\n",
    "    pdf['lat'] = pdf.nodes.apply(lambda x: x.lat)\n",
    "    pdf['lon'] = pdf.nodes.apply(lambda x: x.lon)\n",
    "    pdf['tags'] = pdf.nodes.apply(lambda x: x.tags)\n",
    "    \n",
    "    if l_keys_to_extract:\n",
    "        for key,default_value in zip(l_keys_to_extract,l_values_default):\n",
    "            pdf[key] = pdf.tags.apply(lambda x: x[key] if key in list(x.keys()) else default_value)\n",
    "\n",
    "    if d_key_replace:\n",
    "        for key,val in d_key_replace.items():\n",
    "            for k2,v2 in val.items():\n",
    "                pdf[key] = pdf[key].str.replace(k2,v2)\n",
    "\n",
    "    if d_parse_types:\n",
    "        for k,v in d_parse_types.items():\n",
    "            pdf[k] = pdf[k].astype(v)\n",
    "\n",
    "    if l_drop_na:\n",
    "        pdf = pdf.dropna(subset=l_drop_na)\n",
    "\n",
    "    if is_gdf:\n",
    "        gdf = gpd.GeoDataFrame(pdf, \n",
    "                                geometry=[geometry.Point(xy) for xy in zip(pdf['lon'], pdf['lat'])],\n",
    "                                crs=4326)\n",
    "            \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import haversine_distances\n",
    "# import numpy as np\n",
    "\n",
    "# def compute_haversine(gdf1:gpd.GeoDataFrame, gdf2:gpd.GeoDataFrame) -> pd.DataFrame:\n",
    "#     gdf1['geometry_radians'] = gdf1.apply(lambda x: (np.radians(x['lon']), np.radians(x['lat'])), axis=1)\n",
    "#     gdf2['geometry_radians'] = gdf2.apply(lambda x: (np.radians(x['lon']), np.radians(x['lat'])), axis=1)\n",
    "\n",
    "#     Earth_radius_km =  6378\n",
    "#     dist = haversine_distances(gdf_cities.geometry_radians.to_list(), gdf1.geometry_radians.to_list()) * Earth_radius_km\n",
    "#     pdf_dist = pd.DataFrame(dist, index = [gdf2.ARS], columns = gdf1.store_name)\n",
    "\n",
    "#     # Get the minimum value for each row\n",
    "#     min_values = pdf_dist.min(axis=1)\n",
    "\n",
    "#     # Get the column name of the minimum value for each row\n",
    "#     min_column_names = pdf_dist.idxmin(axis=1)\n",
    "\n",
    "#     # Combine the results\n",
    "#     result = pd.DataFrame({'min_dist_km': min_values, 'dist_min_store': min_column_names}).reset_index()\n",
    "#     result['dist'] = round(result['min_dist_km'], round_dec)\n",
    "#     return result\n",
    "\n",
    "# gdf_result = compute_haversine(gdf1= gdf_stores, gdf2=gdf_cities)\n",
    "# gdf_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lon_min=7.511871829787792, lat_min=47.27012360082152, lon_max=13.839584445443245, lat_max=50.564224739349456\n"
     ]
    }
   ],
   "source": [
    "gdf_cm = gdf_census.groupby('SN_L').agg( \\\n",
    "        {'EWZ':'sum', \n",
    "        'KFL' : 'sum',\n",
    "        'geometry': lambda x: x.geometry.union_all(),\n",
    "        })\n",
    "gdf_cm = gpd.GeoDataFrame(gdf_cm,geometry='geometry', crs=6933).to_crs(4326).reset_index()\n",
    "gdf_cm\n",
    "\n",
    "\n",
    "lon_min, lat_min, lon_max, lat_max = gdf_cm.union_all().bounds\n",
    "print(f'lon_min={lon_min}, lat_min={lat_min}, lon_max={lon_max}, lat_max={lat_max}')\n",
    "# lat_min, lon_min, lat_max, lon_max = 47.53236,7.511872,49.791478,10.495749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_regions:['Bayern', 'Baden-Württemberg']\n",
      "l_stores:['sportscheck', 'decathlon', 'intersport']\n",
      "radius_km:20\n",
      "gdf_circles 168\n",
      "gdf_stores  168\n",
      "gdf_census  3332\n"
     ]
    }
   ],
   "source": [
    "print(f'l_regions:{l_states}')\n",
    "print(f'l_stores:{l_stores}')\n",
    "print(f'radius_km:{radius_km}')\n",
    "print(f'gdf_circles {gdf_circles.shape[0]}')\n",
    "print(f'gdf_stores  {gdf_stores.shape[0]}')\n",
    "print(f'gdf_census  {gdf_census.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. `d_roi` [RoI, Towns, Stores, Circles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape=2\n",
      "# Stores chain selected:168\n"
     ]
    }
   ],
   "source": [
    "### (fg_roi_region) ALL RoI ###\n",
    "### (fg_roi_town)   ALL TOWNS RELEVANT TO RoI ###\n",
    "### (fg_mk_storeall) ALL STORES RELEVANT TO RoI ###\n",
    "### (fg_circ_store)  ALL CIRCLES RELEVANT TO RoI ###\n",
    "\n",
    "from src.functionality_maps import f_maps, f_gadm\n",
    "\n",
    "\n",
    "l_fg_roi = []\n",
    "if maps_roi_is_roi:\n",
    "    fg_roi_pop = round(gdf_census_merged.EWZ.sum() / 10**6, round_dec)\n",
    "    fg_roi_area = gdf_census_merged.area_geom.sum()\n",
    "    fg_legend = f'[{len(l_states)}] GEOM/REGIONS [Sum(Pop):{fg_roi_pop}M, Sum(Area):{fg_roi_area}Km2]'\n",
    "    print(f'Shape={gdf_census_merged.shape[0]}')\n",
    "\n",
    "    fg_roi_region = folium.FeatureGroup(name=fg_legend)\n",
    "    gjson_store = f_maps.get_folium_geojson( gdf_census_merged, \n",
    "                                    fields=['Bundesland', 'EWZ', 'area_geom'],\n",
    "                                    aliases = ['Bundesland', 'Pop', 'Area_geom[Km2]']\n",
    "                                    )\n",
    "    gjson_store.add_to(fg_roi_region)\n",
    "    l_fg_roi += [fg_roi_region] \n",
    "\n",
    "if maps_roi_is_towns:\n",
    "    num_towns = gdf_census.shape[0]\n",
    "    fg_roi_pop = round(gdf_census.EWZ.sum() / 10**6, round_dec)\n",
    "    fg_roi_area = gdf_census.to_crs(6933).area_geom.sum()\n",
    "\n",
    "    legend_roi_town = f'[{num_towns}] GEOM/TOWNS'\n",
    "\n",
    "\n",
    "    fg_roi_town = folium.FeatureGroup(name=legend_roi_town, show=False)\n",
    "    gjson_store = f_maps.get_folium_geojson(gdf_census.to_crs(4326), \n",
    "                                    fields=['GEN', 'EWZ', 'area_geom', 'KFL'],\n",
    "                                    aliases = ['Town', 'Pop', 'Area_geom[km2]', 'Area_dbms[Km2]'],\n",
    "                                    )\n",
    "    gjson_store.add_to(fg_roi_town)\n",
    "    l_fg_roi += [fg_roi_town]\n",
    "\n",
    "if maps_roi_is_stores:\n",
    "    print(f'# Stores chain selected:{gdf_stores.shape[0]}')\n",
    "    fg_mk_storeall = f_gadm.get_fg_store(gdf_stores, l_stores)\n",
    "    l_fg_roi += fg_mk_storeall\n",
    "\n",
    "if maps_roi_is_circles:\n",
    "    print(f'Shape Circles RoI:{gdf_stores.shape[0]}')\n",
    "    gdf_circles_stores_all = f_maps.get_gdf_circle(df=gdf_stores, radius_km= radius_km).drop(['point'], axis=1)\n",
    "    fg_circ_store = f_maps.get_fg_gjson(gdf=gdf_circles_stores_all, fg_name=f'Circles [r={radius_km}Km]',\n",
    "                                        fields=['store','name', 'address'],\n",
    "                                        aliases = ['store', 'name', 'address'])\n",
    "    l_fg_roi +=  [fg_circ_store]\n",
    "\n",
    "\n",
    "### ADDING FG into GroupedLayerControl\n",
    "fglc_geom = folium.plugins.GroupedLayerControl(\n",
    "    groups={'Region of Interest [RoI]': l_fg_roi},\n",
    "    exclusive_groups=False,\n",
    "    collapsed=False,\n",
    ")\n",
    "d_roi = {\n",
    "    'l_fg' : l_fg_roi,\n",
    "    'fglc' : fglc_geom\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 `d_poi` [Mountains,campings,climb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pip install overpass\n",
    "# %pip install overpy\n",
    "# import overpy\n",
    "# api = overpy.Overpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOUNTAINS\n",
      "  # of mountains= 11695\n",
      "  # of mountains [min_ele>1000.0]= 2399\n",
      "CAMPINGS\n",
      "  # Campings= 351\n",
      "  # Campings with Capacity > 20 = [161]\n",
      "CLIMBINGS\n",
      "  # of Climbing facilities= 1050\n"
     ]
    }
   ],
   "source": [
    "d_poi = {\n",
    "   'd_gdf' : {}\n",
    "}\n",
    "l_fg_poi = []\n",
    "\n",
    "### MOUNTAINS ###\n",
    "if maps_poi_mountains:\n",
    "   print('MOUNTAINS')\n",
    "   # Extract from OSM\n",
    "   gdf_mountains_bound = gen_pdf_osm(lat_min, lon_min, lat_max, lon_max, args='natural=peak',\n",
    "                           l_keys_to_extract = ['name','ele'],\n",
    "                           l_values_default = ['', 'nan'],\n",
    "                           d_key_replace = {'ele' : {',' : '.', 'm':''}},\n",
    "                           d_parse_types = {'lat' : float, 'lon': float, 'ele' : float},\n",
    "                           l_drop_na=['lat','lon','ele']\n",
    "                           )\n",
    "   # Drop columns that are not needed\n",
    "   gdf_mountains_bound = gdf_mountains_bound.drop(['nodes','tags'], axis=1)\n",
    "   # Intersect with GDF with Region of Interest\n",
    "   gdf_mountains = gpd.sjoin(gdf_mountains_bound.to_crs(epsg=4326),\n",
    "                                 gdf_cm[['geometry']].to_crs(epsg=4326), \n",
    "                                 how=\"inner\", predicate=\"intersects\")\n",
    "   print(f'  # of mountains= {gdf_mountains.shape[0]}')\n",
    "\n",
    "   # # Filter for elevation\n",
    "   gdf_mountains = gdf_mountains[gdf_mountains['ele']>=mountains_min_elev]\n",
    "   print(f'  # of mountains [min_ele>{mountains_min_elev}]= {gdf_mountains.shape[0]}')\n",
    "   # gdf_mountains.head()\n",
    "\n",
    "   # Feature Group\n",
    "   fg_mountains = folium.FeatureGroup(name=f'[{gdf_mountains.shape[0]}] Mountains min_elev>{mountains_min_elev}m', show=False)\n",
    "   for index, row in gdf_mountains.iterrows():\n",
    "      folium.Marker(location=[row[\"lat\"], row[\"lon\"]],\n",
    "                     popup=f'{row[\"name\"]} \\r\\n {row[\"ele\"]}m',\n",
    "                     tooltip=row[\"name\"],\n",
    "                     icon=folium.features.CustomIcon(icon_image='assets/Geo/mountain.png',\n",
    "                                                      icon_size=(20, 20))\n",
    "                     ).add_to(fg_mountains)\n",
    "   # d_poi['mountains'] = fg_mountains\n",
    "   l_fg_poi += [fg_mountains]\n",
    "   d_poi['d_gdf']['mountains'] = gdf_mountains\n",
    "   \n",
    "   ### MARKETCLUSTER MOUNTAINS ###\n",
    "   if maps_poi_mountains_clusters:\n",
    "      fields = ['name', 'ele']\n",
    "      aliases = ['Name', 'Elevation [m]']\n",
    "      tooltip = folium.features.GeoJsonTooltip(\n",
    "                  fields=fields,\n",
    "                  aliases=aliases\n",
    "            )\n",
    "      if (gdf_mountains.shape[0] > 0):\n",
    "         cluster_mountains = folium.plugins.MarkerCluster(locations=gdf_mountains[['lat','lon']],\n",
    "                                                name='Mountains (Clustered)', show=False\n",
    "                        )\n",
    "         # d_poi['clusters_mountains'] = cluster_mountains\n",
    "         l_fg_poi += [cluster_mountains]\n",
    "\n",
    "   ### CIRCLES MOUNTAINS ###\n",
    "   if maps_poi_mountains_circles:\n",
    "      gdf_mountains_circles = f_maps.get_gdf_circle(df=gdf_mountains[['name','lon','lat','ele']], radius_km= radius_km)\n",
    "      fg_circ_mountain = f_maps.get_fg_gjson(gdf=gdf_mountains_circles, fg_name=f'Circles [r={radius_km}Km]',\n",
    "                                    fields=['name'],\n",
    "                                    aliases = ['name'],\n",
    "                                    # fill_color = d_inputs['stores'][store_sel]['color']\n",
    "                                    )\n",
    "      \n",
    "      l_fg_poi += [fg_circ_mountain]\n",
    "      if is_logging:\n",
    "            print(f' # Mountain Circles ={gdf_mountains_circles.shape[0]}')\n",
    "\n",
    "\n",
    "\n",
    "### CAMPINGS ###\n",
    "if maps_poi_campings:\n",
    "   print('CAMPINGS')\n",
    "   # Extract from OSM\n",
    "   gdf_campings_bound = gen_pdf_osm(lat_min, lon_min, lat_max, lon_max, args='tourism=camp_site',\n",
    "                           l_keys_to_extract = ['name','tourism','capacity'],\n",
    "                           l_values_default = ['','','nan'],\n",
    "                           d_key_replace = {'capacity' : {'ab' : '', 'maximal' : '', 'unknown' : 'nan'}},\n",
    "                           d_parse_types = {'capacity' : float},\n",
    "                           # l_drop_na=['capacity']\n",
    "                           )\n",
    "   print(f'  # Campings= {gdf_campings_bound.shape[0]}')\n",
    "\n",
    "   # Drop columns that are not needed\n",
    "   gdf_campings_bound = gdf_campings_bound.drop(['nodes','tags'], axis=1)\n",
    "\n",
    "   # Intersect with GDF with Region of Interest\n",
    "   gdf_campings = gpd.sjoin(gdf_campings_bound.to_crs(epsg=4326),\n",
    "                                 gdf_cm[['geometry']].to_crs(epsg=4326), \n",
    "                                 how=\"inner\", predicate=\"intersects\")\n",
    "   # Filter\n",
    "   # min_capacity = 30\n",
    "   # gdf_campings = gdf_campings[gdf_campings['capacity'] > min_capacity]\n",
    "   print(f'  # Campings with Capacity > {campings_min_capacity} = [{gdf_campings.shape[0]}]')\n",
    "   # gdf_campings.head()\n",
    "\n",
    "   # Feature Group\n",
    "   fg_campings = folium.FeatureGroup(name=f'[{gdf_campings.shape[0]}] Campings capacity > {campings_min_capacity}', show=False)\n",
    "   for index, row in gdf_campings.iterrows():\n",
    "      folium.Marker(location=[row[\"lat\"], row[\"lon\"]],\n",
    "                     popup=row[\"capacity\"],\n",
    "                     tooltip=row[\"name\"],\n",
    "                     icon=folium.features.CustomIcon(icon_image='assets/Geo/camping.png',\n",
    "                                                      icon_size=(25, 25))\n",
    "                     ).add_to(fg_campings)\n",
    "   l_fg_poi += [fg_campings] \n",
    "   d_poi['d_gdf']['campings'] = gdf_campings\n",
    "   \n",
    "   ### MARKETCLUSTER CAMPINGS ###\n",
    "   if maps_poi_cluster_campings:\n",
    "      fields = ['name', 'ele']\n",
    "      aliases = ['Name', 'Elevation [m]']\n",
    "      tooltip = folium.features.GeoJsonTooltip(\n",
    "                  fields=fields,\n",
    "                  aliases=aliases\n",
    "            )\n",
    "      if (gdf_campings.shape[0] > 0):\n",
    "         cluster_campings = folium.plugins.MarkerCluster(locations=gdf_campings[['lat','lon']],\n",
    "                                                name='Campings (Clustered)', show=False\n",
    "                        )\n",
    "         l_fg_poi += [cluster_campings] \n",
    "\n",
    "\n",
    "\n",
    "### CLIMBINGS ###\n",
    "if maps_poi_climbings:\n",
    "   print('CLIMBINGS')\n",
    "   # Extract from OSM\n",
    "   gdf_climbings_bound = gen_pdf_osm(lat_min, lon_min, lat_max, lon_max, args='sport=climbing',\n",
    "                           l_keys_to_extract = ['name','climbing','natural','website','addr:city'],\n",
    "                           l_values_default = ['','','','nan',''],\n",
    "                           # d_key_replace = {'capacity' : {'ab' : '', 'maximal' : ''}},\n",
    "                           # d_parse_types = {'capacity' : float},\n",
    "                           l_drop_na=['website']\n",
    "                           )\n",
    "   # Drop columns that are not needed\n",
    "   gdf_climbings_bound = gdf_climbings_bound.drop(['nodes','tags'], axis=1)\n",
    "   # Intersect with GDF with Region of Interest\n",
    "   gdf_climbings = gpd.sjoin(gdf_climbings_bound.to_crs(epsg=4326),\n",
    "                                 gdf_cm[['geometry']].to_crs(epsg=4326), \n",
    "                                 how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "   # Filter\n",
    "   print(f'  # of Climbing facilities= {gdf_climbings.shape[0]}')\n",
    "\n",
    "   # Feature Group\n",
    "   fg_climb = folium.FeatureGroup(name=f' [{gdf_climbings.shape[0]}] Climb Facilities', show=False)\n",
    "   for index, row in gdf_climbings.iterrows():\n",
    "      folium.Marker(location=[row[\"lat\"], row[\"lon\"]],\n",
    "                     popup=row[\"website\"],\n",
    "                     tooltip=row[\"name\"],\n",
    "                     icon=folium.features.CustomIcon(icon_image='assets/Geo/climbing_no_rope.png',\n",
    "                                                      icon_size=(25, 25))\n",
    "                     ).add_to(fg_climb)\n",
    "   l_fg_poi += [fg_climb] \n",
    "   d_poi['d_gdf']['climbings'] = gdf_climbings\n",
    "\n",
    "   ### MARKETCLUSTER CLIMBINGS ###\n",
    "   if maps_poi_cluster_climbings:\n",
    "      fields = ['name', 'ele']\n",
    "      aliases = ['Name', 'Elevation [m]']\n",
    "      tooltip = folium.features.GeoJsonTooltip(\n",
    "                  fields=fields,\n",
    "                  aliases=aliases\n",
    "            )\n",
    "      if (gdf_climbings.shape[0] > 0):\n",
    "         cluster_climbings = folium.plugins.MarkerCluster(locations=gdf_climbings[['lat','lon']],\n",
    "                                                name='Climbings (Clustered)', show=False,\n",
    "                        )\n",
    "         l_fg_poi += [cluster_climbings] \n",
    "\n",
    "\n",
    "### ADDING FG into GroupedLayerControl\n",
    "fglc_poi = folium.plugins.GroupedLayerControl(\n",
    "    groups={'Point(s) of Interest [PoI]': l_fg_poi},\n",
    "    exclusive_groups=False,\n",
    "    collapsed=False,\n",
    ")\n",
    "\n",
    "d_poi['l_fg'] = l_fg_poi\n",
    "d_poi['fglc'] = fglc_poi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. `d_stores` [Join,Intersection,Merge,Union(int),Union(merge)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "### VARIABLES FOR LOOP BELOW ###\n",
    "col_perc_dbms = 'PERC_dbms_int'\n",
    "col_perc_geom = 'PERC_roi_int'\n",
    "col_perc_pop = 'PERC_pop'\n",
    "l_cols_percentaged = ['area_geom', 'EWZ', 'KFL']\n",
    "\n",
    "d_columns = {\n",
    "    'area_geom':{'alias': 'area',         'is_norm': True,  'is_int':False},\n",
    "    'KFL':     {'alias' : 'area_data',    'is_norm': True,  'is_int':False},\n",
    "    'EWZ':     {'alias' : 'Population',   'is_norm': True,  'is_int':True}\n",
    "}\n",
    "# print(f'[{len(l_bundeslaender)}] # Towns: {gdf_census.shape[0]}/ #Stores={gdf_stores.shape[0]} / #Circles={gdf_circles.shape[0]}')\n",
    "# gdf_circles_region.store_name.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi=mountains\n",
      "poi=campings\n",
      "poi=climbings\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_name</th>\n",
       "      <th>location</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>store</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>geometry</th>\n",
       "      <th>mountains</th>\n",
       "      <th>campings</th>\n",
       "      <th>climbings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sportscheck_karlsruhe</td>\n",
       "      <td>{'address': 'SportScheck, 92, Kaiserstraße, In...</td>\n",
       "      <td>8.401156</td>\n",
       "      <td>49.009848</td>\n",
       "      <td>sportscheck</td>\n",
       "      <td>karlsruhe</td>\n",
       "      <td>Kaiserstraße 92, 76133 Karlsruhe</td>\n",
       "      <td>POLYGON ((8.67537 49.00952, 8.67395 48.9919, 8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              store_name                                           location  \\\n",
       "0  sportscheck_karlsruhe  {'address': 'SportScheck, 92, Kaiserstraße, In...   \n",
       "\n",
       "        lon        lat        store       name  \\\n",
       "0  8.401156  49.009848  sportscheck  karlsruhe   \n",
       "\n",
       "                            address  \\\n",
       "0  Kaiserstraße 92, 76133 Karlsruhe   \n",
       "\n",
       "                                            geometry  mountains  campings  \\\n",
       "0  POLYGON ((8.67537 49.00952, 8.67395 48.9919, 8...          0         0   \n",
       "\n",
       "   climbings  \n",
       "0          7  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add PoI info to gdf_circles ###\n",
    "gdf_circles = gdf_stores[['store_name','location']].merge(gdf_circles,on='store_name')\n",
    "# Converting the PDF in GDF\n",
    "gdf_circles = gpd.GeoDataFrame(gdf_circles, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "if maps_stores_is_pois and bool(d_poi['d_gdf']):\n",
    "    l_cols_poi = list(d_poi['d_gdf'].keys())\n",
    "    for poi,gdf_poi in d_poi['d_gdf'].items():\n",
    "        if is_logging:\n",
    "            print(f'poi={poi}')\n",
    "        gdf_circles[poi] = gdf_circles.apply(lambda row : \n",
    "                                             gpd.sjoin(\n",
    "                                                 gpd.GeoDataFrame({'geometry': [row['geometry']]}, geometry='geometry', crs=\"EPSG:4326\"),  \n",
    "                                                 gdf_poi[['geometry']], how=\"inner\", predicate=\"intersects\").shape[0], axis=1)\n",
    "gdf_circles.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Region=09/Bayern/ # Towns: 2229/ #Stores=89 / #Circles=89\n",
      "  [1/3] Store=sportscheck / # Stores = 0/ # Circles = 0\n",
      "  [2/3] Store=decathlon / # Stores = 15/ # Circles = 15\n",
      " # Stores =15\n",
      " # Circles =15\n",
      " # Merges =15\n",
      " # Union (intersection) =617\n",
      " # Union (Merge) =6040839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15920\\3195688538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [3/3] Store=intersport / # Stores = 74/ # Circles = 74\n",
      " # Stores =74\n",
      " # Circles =74\n",
      " # Merges =74\n",
      " # Union (intersection) =1650\n",
      " # Union (Merge) =9440646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15920\\3195688538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/2] Region=08/Baden-Württemberg/ # Towns: 1103/ #Stores=98 / #Circles=98\n",
      "  [1/3] Store=sportscheck / # Stores = 3/ # Circles = 3\n",
      " # Stores =3\n",
      " # Circles =3\n",
      " # Merges =3\n",
      " # Union (intersection) =147\n",
      " # Union (Merge) =2667008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15920\\3195688538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/3] Store=decathlon / # Stores = 17/ # Circles = 17\n",
      " # Stores =17\n",
      " # Circles =17\n",
      " # Merges =17\n",
      " # Union (intersection) =540\n",
      " # Union (Merge) =6505872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15920\\3195688538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [3/3] Store=intersport / # Stores = 78/ # Circles = 78\n",
      " # Stores =78\n",
      " # Circles =78\n",
      " # Merges =78\n",
      " # Union (intersection) =1077\n",
      " # Union (Merge) =10618382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_15920\\3195688538.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  gdf2['coords'] = gdf2.apply(lambda x: (x['lat'], x['lon']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "### [d_stores] --> LOOP PROCESSING [Region[Store]] ###\n",
    "from src.functionality_maps import f_maps, f_gadm\n",
    "\n",
    "d_stores = {}\n",
    "for j,region_name in enumerate(l_states):\n",
    "    d_fglc = {}\n",
    "\n",
    "    region_no = Defs.dict_bundeslaender_id[region_name]\n",
    "    ### FILTER BY REGION ###\n",
    "    gdf_census_region = gdf_census[gdf_census['SN_L'] == region_no]\n",
    "    gdf_circles_region = gpd.sjoin(gdf_circles, gdf_census_region[['geometry']].to_crs(4326), how=\"inner\", predicate=\"intersects\")\n",
    "    gdf_circles_region_no_loc = gdf_circles_region.drop(['location','index_right'], axis=1).drop_duplicates()\n",
    "\n",
    "    gdf_circles_region = gdf_stores[['store_name','location']].merge(gdf_circles_region_no_loc,on='store_name')\n",
    "    gdf_circles_region = gpd.GeoDataFrame(gdf_circles_region, geometry='geometry', crs=\"EPSG:4326\")\n",
    "\n",
    "    gdf_stores_region = gdf_stores[gdf_stores['store_name'].isin(gdf_circles_region.store_name.to_list())]\n",
    "    print(f'[{j+1}/{len(l_bundeslaender)}] Region={region_no}/{region_name}/ ' +\n",
    "          f'# Towns: {gdf_census_region.shape[0]}/ #Stores={gdf_stores_region.shape[0]} / #Circles={gdf_circles_region.shape[0]}')\n",
    "    \n",
    "    for i,store_sel in enumerate(l_stores):\n",
    "        l_fg_store = []\n",
    "        ### FILTER BY STORE ###\n",
    "        gdf_stores_region_stores = gdf_stores_region[gdf_stores_region['store'] == store_sel]\n",
    "        gdf_circles_region_stores = gdf_circles_region[gdf_circles_region['store'] == store_sel]\n",
    "        # gdf_circles_region_stores = gdf_stores_region_stores[['store_name','location']].merge(gdf_circles_region,on='store_name')\n",
    "        # gdf_circles_region_stores = gpd.GeoDataFrame(gdf_circles_region_stores, geometry='geometry',crs=\"EPSG:4326\")\n",
    "        print(f'  [{i+1}/{len(l_stores)}] Store={store_sel} / # Stores = {gdf_stores_region_stores.shape[0]}/ ' \\\n",
    "              f'# Circles = {gdf_circles_region_stores.shape[0]}')\n",
    "\n",
    "        if gdf_circles_region_stores.shape[0] == 0:\n",
    "            continue\n",
    "        ### Stores ###\n",
    "        if maps_stores_is_stores:\n",
    "            ### PoIs ###\n",
    "            if maps_stores_is_pois and bool(d_poi['d_gdf']):\n",
    "                # l_cols_poi = list(d_poi['d_gdf'].keys())\n",
    "                # for poi,gdf_poi in d_poi['d_gdf'].items():\n",
    "                #     if is_logging:\n",
    "                #         print(f'poi={poi}')\n",
    "                #     gdf_circles_region_stores[poi] = gdf_circles_region_stores.apply(lambda row : \n",
    "                #                                                             gpd.sjoin(gpd.GeoDataFrame({'geometry': [row['geometry']]}, geometry='geometry', crs=\"EPSG:4326\"),  \n",
    "                #                                                                     gdf_poi[['geometry']], how=\"inner\", predicate=\"intersects\").shape[0], axis=1)\n",
    "                fg_mk_store = f_gadm.get_fg_store(pdf=gdf_circles_region_stores, l_stores=[store_sel], \n",
    "                                                  l_popup_rows = l_cols_poi)\n",
    "            else:\n",
    "                fg_mk_store = f_gadm.get_fg_store(pdf=gdf_stores_region_stores, l_stores=[store_sel])\n",
    "            fg_mk_store = fg_mk_store[0]\n",
    "            l_fg_store.append(fg_mk_store)\n",
    "            if is_logging:\n",
    "                print(f' # Stores ={gdf_stores_region_stores.shape[0]}')\n",
    "\n",
    "        ### Circles ###\n",
    "        if maps_stores_is_circles:\n",
    "            fg_circ_store = f_maps.get_fg_gjson(gdf=gdf_circles_region_stores, fg_name=f'Circles [r={radius_km}Km]',\n",
    "                                        fields=['store','name', 'address'],\n",
    "                                        aliases = ['store', 'name', 'address'],\n",
    "                                        fill_color = d_inputs['stores'][store_sel]['color'])\n",
    "            l_fg_store.append(fg_circ_store)\n",
    "            if is_logging:\n",
    "                print(f' # Circles ={gdf_circles_region_stores.shape[0]}')\n",
    "\n",
    "\n",
    "        ### Join ###\n",
    "        if maps_stores_is_join:\n",
    "            gdf_circles_all_store = gdf_circles[gdf_circles['store'] == store_sel]\n",
    "            gdf_joi_circ_geom_store = gpd.sjoin(gdf_census_region.to_crs(epsg=4326), gdf_circles_region_stores.to_crs(4326), how=\"inner\", predicate=\"intersects\")\n",
    "            gdf_joi_circ_geom_store['area'] = round(gdf_census_region.geometry.area / 10**6, round_dec)\n",
    "            fg_joi_circ_geom_store = f_maps.get_fg_gjson(gdf=gdf_joi_circ_geom_store, fg_name=f'Join',\n",
    "                                                    fields=['GEN', 'EWZ', 'KFL', 'area'],\n",
    "                                                    aliases = ['Name', 'Population', 'Area_dbms', 'Area_Geom'])\n",
    "            l_fg_store.append(fg_joi_circ_geom_store)\n",
    "            if is_logging:\n",
    "                print(f' # Joins ={gdf_joi_circ_geom_store.shape[0]}')\n",
    "\n",
    "        ### INTERSECTION ###\n",
    "        cols = ['geometry','store','store_name'] + l_cols_poi\n",
    "        gdf_int_circ_geom = gpd.overlay(gdf_census_region, \n",
    "                                        gdf_circles_region_stores[cols].to_crs(6933), \n",
    "                                        how='intersection')\n",
    "        gdf_int_circ_geom['area'] = round(gdf_int_circ_geom.geometry.area / 10**6, round_dec)\n",
    "        gdf_int_circ_geom[col_perc_geom] = round(gdf_int_circ_geom['area'] / gdf_int_circ_geom['area_geom'], 3)\n",
    "        \n",
    "        gdf_overlay = f_maps.overlay_shapes(gdf_circle=gdf_int_circ_geom,\n",
    "                                            col_perc=col_perc_geom, \n",
    "                                            d_columns=d_columns)\n",
    "        gdf_overlay[col_perc_dbms] = round(gdf_overlay['KFL_int'] / gdf_overlay['KFL'], 3)\n",
    "        gdf_overlay[col_perc_pop] = round(gdf_overlay['EWZ_int'] / gdf_overlay['EWZ'], 3)\n",
    "\n",
    "        fg_int_circ_geom_store = f_maps.get_fg_gjson(gdf=gdf_overlay, fg_name=f'Intersection',\n",
    "                                    fields=['GEN', 'store_name', \n",
    "                                            'area_geom_int', 'area_geom', col_perc_geom,\n",
    "                                            'EWZ_int', 'EWZ', col_perc_pop],\n",
    "                                    aliases = ['City', 'Store name', \n",
    "                                            'Area inside[Km2]', 'Area shape[Km2]', 'Area perc[%]',\n",
    "                                            'Pop inside', 'Pop total', 'Pop perc[%]'])\n",
    "        if maps_stores_is_intersection:\n",
    "            l_fg_store.append(fg_int_circ_geom_store)\n",
    "            if is_logging:\n",
    "                print(f' # Intersections ={gdf_overlay.shape[0]}')\n",
    "        \n",
    "        ### Merge ###\n",
    "        gdf_mer_circ_geom = gdf_int_circ_geom.groupby(['store','store_name']).agg( \\\n",
    "            {'geometry': lambda x: x.geometry.union_all(),\n",
    "            'EWZ_int':'sum', \n",
    "            'EWZ':'sum', \n",
    "            'KFL_int' : 'sum',\n",
    "            'KFL' : 'sum',\n",
    "            'area_geom_int' : 'sum',\n",
    "            'area_geom' : 'sum'\n",
    "            }).set_geometry(\"geometry\").set_crs(6933).reset_index()\n",
    "\n",
    "        # Set the column used for NORMALIZATION (numerator)\n",
    "        gdf_mer_circ_geom[col_perc_geom] = round(gdf_mer_circ_geom['area_geom_int'] / gdf_mer_circ_geom['area_geom'], 3)\n",
    "        gdf_mer_circ_geom[col_perc_dbms] = round(gdf_mer_circ_geom['KFL_int'] / gdf_mer_circ_geom['KFL'], 3)\n",
    "        gdf_mer_circ_geom[col_perc_pop]  = round(gdf_mer_circ_geom['EWZ_int'] / gdf_mer_circ_geom['EWZ'], 3)\n",
    "        \n",
    "        fg_mer_circ_geom_store = f_maps.get_fg_gjson(gdf=gdf_mer_circ_geom, fg_name=f'Merge',\n",
    "                                    fields=['store', 'store_name', \n",
    "                                            'area_geom_int', 'area_geom', col_perc_geom,\n",
    "                                            'EWZ_int', 'EWZ', col_perc_pop],\n",
    "                                    aliases = ['Store_chain', 'Store name', \n",
    "                                                'Area inside[Km2]', 'Area shape[Km2]', 'Area perc[%]',\n",
    "                                                'Pop inside', 'Pop total', 'Pop perc[%]'],\n",
    "                                    is_styled = True,\n",
    "                                    fill_color = d_inputs['stores'][store_sel]['color'])\n",
    "        if maps_stores_is_merge:\n",
    "            l_fg_store.append(fg_mer_circ_geom_store)\n",
    "        if is_logging:\n",
    "                print(f' # Merges ={gdf_mer_circ_geom.shape[0]}')\n",
    "\n",
    "        ### Union (Intersection) ###\n",
    "        poly_merged = gdf_mer_circ_geom.geometry.union_all()\n",
    "        gdf_poly_merged = gpd.GeoSeries([poly_merged]).to_frame(name='geometry').set_crs(epsg=6933)\n",
    "        \n",
    "        gdf_merge2 = gpd.overlay(gdf_census_region, gdf_poly_merged, how='intersection')\n",
    "        gdf_merge2['area'] = round(gdf_merge2.geometry.area / 10**6, round_dec)\n",
    "        gdf_merge2[col_perc_geom] = round(gdf_merge2['area'] / gdf_merge2['area_geom'], 3)\n",
    "\n",
    "        gdf_overlay2 = f_maps.overlay_shapes(gdf_circle=gdf_merge2, col_perc=col_perc_geom, d_columns=d_columns)\n",
    "        gdf_overlay2['num_stores'] = gdf_mer_circ_geom.shape[0]\n",
    "        gdf_overlay2['store_chain'] = store_sel\n",
    "        gdf_overlay2['area'] = round(gdf_overlay2.geometry.area / 10**6, round_dec)\n",
    "\n",
    "        fg_uni_circ_geom_store = f_maps.get_fg_gjson(gdf=gdf_overlay2.to_crs(4326), fg_name=f'Union (Intersection)',\n",
    "                                    fields=   ['GEN', 'store_chain', 'area', 'EWZ_int'],\n",
    "                                    aliases = ['City','Store chain', 'Area GEN[Km2]', 'Pop'],\n",
    "                                    is_styled = True,\n",
    "                                    fill_color = d_inputs['stores'][store_sel]['color'])\n",
    "        if maps_stores_is_union_intersection:\n",
    "            l_fg_store.append(fg_uni_circ_geom_store)\n",
    "        if is_logging:\n",
    "            print(f' # Union (intersection) ={gdf_overlay2.shape[0]}')\n",
    "\n",
    "        ### Union (Merge) ###\n",
    "        gdf_store_circles_merged_union = gdf_overlay2.groupby(['store_chain','num_stores']).agg( \\\n",
    "            {'geometry': lambda x: x.geometry.union_all(),\n",
    "            'EWZ_int':'sum', \n",
    "            'area' : 'sum',\n",
    "            }).set_geometry(\"geometry\").set_crs(6933).reset_index()\n",
    "        \n",
    "        gdf_store_circles_merged_union['area_total'] = round(gdf_census_region.geometry.area.sum() / 10**6, 3)\n",
    "        gdf_store_circles_merged_union[col_perc_geom] = round(100*gdf_store_circles_merged_union['area'] / gdf_store_circles_merged_union['area_total'], round_dec)\n",
    "\n",
    "        gdf_store_circles_merged_union['EWZ_int_milions'] = round(gdf_store_circles_merged_union['EWZ_int'] / 10**6, round_dec)\n",
    "        gdf_store_circles_merged_union['EWZ_total_milions'] = round(gdf_census_region.EWZ.sum()/10**6, 3)\n",
    "        gdf_store_circles_merged_union[col_perc_pop] = round(100*gdf_store_circles_merged_union['EWZ_int_milions'] / gdf_store_circles_merged_union['EWZ_total_milions'], round_dec)\n",
    "\n",
    "        fg_mer_uni_circ_geom_store = f_maps.get_fg_gjson(gdf=gdf_store_circles_merged_union.to_crs(4326), fg_name=f'Union (Merge)',\n",
    "                                        fields=['store_chain', 'num_stores',\n",
    "                                                'area', 'area_total', col_perc_geom, \n",
    "                                                'EWZ_int_milions', 'EWZ_total_milions', col_perc_pop],\n",
    "                                        aliases = ['Store chain','# Stores',\n",
    "                                                'Area stores[Km2]', 'Area RoI[Km2]', 'Area perc[%]', \n",
    "                                                'Pop[M]', 'Pop RoI[M]','Pop perc[%]'],\n",
    "                                        is_styled = True,\n",
    "                                        fill_color = d_inputs['stores'][store_sel]['color'])\n",
    "\n",
    "        if maps_stores_is_union_merge:\n",
    "            l_fg_store.append(fg_mer_uni_circ_geom_store)\n",
    "        if is_logging:\n",
    "            print(f' # Union (Merge) ={gdf_store_circles_merged_union.EWZ_int.sum()}')\n",
    "\n",
    "\n",
    "        col_interest = ['ARS','lat','lon',col_perc_geom,'GEN', 'area_geom_int', 'area_geom', 'EWZ_int', 'EWZ']\n",
    "        gdf_cities = gdf_overlay2[col_interest]\n",
    "        pdf_dist = pairwise_min_dist(gdf1=gdf_stores_region, gdf2=gdf_cities)\n",
    "        gdf_dist = pdf_dist[['ARS','dist','dist_min_store']].merge(gdf_overlay2, on='ARS', how='right')\n",
    "\n",
    "        ###  INSIDE  ###\n",
    "        if maps_stores_is_markers_inside:\n",
    "            gdf_inside = gdf_dist[gdf_dist[col_perc_geom] >= 1.0]\n",
    "            fg_markers_inside = get_fg_markers_region(gdf=gdf_inside, position = 'inside', color='darkgreen',\n",
    "                                                       round_dec=round_dec, is_shown = False, is_logging=is_logging)\n",
    "            l_fg_store.append(fg_markers_inside)\n",
    "            if is_logging:\n",
    "                print(f' # Markers Inside [Towns={gdf_inside.shape[0]}/ Pop={gdf_inside.EWZ_int.sum()}]')\n",
    "  \n",
    "        ###  PARTLY  ###\n",
    "        if maps_stores_is_markers_partly:\n",
    "            gdf_partly = gdf_dist[gdf_dist[col_perc_geom] < 1.0]\n",
    "            fg_markers_partly = get_fg_markers_region(gdf=gdf_partly, position = 'partly', color='orange', \n",
    "                                                      round_dec=round_dec, is_shown = False, is_logging=is_logging)\n",
    "            l_fg_store.append(fg_markers_partly)\n",
    "            if is_logging:\n",
    "                print(f' # Markers Partly [Towns={gdf_partly.shape[0]}/ Pop={gdf_partly.EWZ_int.sum()}]')\n",
    " \n",
    "        ###  OUTSIDE  ###\n",
    "        if maps_stores_is_markers_outside:\n",
    "            gdf_outside = gdf_census_region[~gdf_census_region['ARS'].isin(gdf_dist['ARS'])]\n",
    "            fg_markers_outside = get_fg_markers_region(gdf=gdf_outside, position = 'outside', color='red', \n",
    "                                                       round_dec=round_dec, is_shown = False, is_logging=is_logging)\n",
    "            l_fg_store.append(fg_markers_outside)\n",
    "            if is_logging:\n",
    "                print(f' # Markers Outside [Towns={gdf_outside.shape[0]}/ Pop={gdf_outside.EWZ.sum()}]')\n",
    " \n",
    "        ### GENERATING GroupedLayerControl FOR STORE ###\n",
    "        fglc_store = folium.plugins.GroupedLayerControl(\n",
    "            groups={f'{region_no}/{region_name}-{store_sel}': l_fg_store},\n",
    "            exclusive_groups=False,\n",
    "            collapsed=False)\n",
    "\n",
    "        ### SAVING IT IN THE DICTIONARY ###\n",
    "        d_fglc[store_sel] = {\n",
    "            'store_name' : store_sel,\n",
    "            'l_children' : l_fg_store,\n",
    "            'fglc' :       fglc_store,\n",
    "        }\n",
    "        if maps_stores_is_union_intersection:\n",
    "            # d_fglc[store_sel]['df_5_merge'] = gdf_mer_circ_geom\n",
    "            d_fglc[store_sel]['df_6_union'] = gdf_overlay2\n",
    "    \n",
    "    d_stores[region_no] = {\n",
    "        'region_no' : region_no,\n",
    "        'region_name' : region_name,\n",
    "        'store' : d_fglc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. `d_stores` [gdf_union_int,gdf_union_,merge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] Region=09/Bayern\n",
      " Region=[Bayern] has NO stores\n",
      "[2/2] Region=08/Baden-Württemberg\n",
      " Region=[Baden-Württemberg] has NO stores\n"
     ]
    }
   ],
   "source": [
    "### MERGING STORES IN THE SAME REGION ###\n",
    "d_stores_merged = {}\n",
    "l_fg_merged_allstores = []\n",
    "\n",
    "for j,(region_no,region_values) in enumerate(d_stores.items()):\n",
    "    print(f'[{j+1}/{len(d_stores)}] Region={region_values['region_no']}/{region_values['region_name']}')\n",
    "    dict_fglc = region_values['store']\n",
    "    if not(dict_fglc):\n",
    "        print(f' Region={region_values['region_name']} has no stores')\n",
    "        continue\n",
    "\n",
    "    gdf_concat_allstores = pd.DataFrame()\n",
    "    for i,(k,v) in enumerate(dict_fglc.items()):\n",
    "        if 'df_6_union' not in list(v.keys()):\n",
    "            # print(f'Region={region_values['region_name']} has no union of stores for store [{k}]')\n",
    "            continue\n",
    "        \n",
    "        print(f'  [{i+1}/{len(dict_fglc)}] Store:{v['store_name']}')\n",
    "        gdf_concat_allstores = pd.concat([gdf_concat_allstores, v['df_6_union']], ignore_index=True)\n",
    "    \n",
    "    if gdf_concat_allstores.empty:\n",
    "        print(f' Region=[{region_values['region_name']}] has NO stores')\n",
    "        continue\n",
    "\n",
    "    gdf_concat_allstores['BL'] = region_values['region_no']\n",
    "    gdf_concat_allstores['State'] = region_values['region_name']\n",
    "    # df['BL'] = 'RoI'\n",
    "\n",
    "    [gdf_union_int_allstores, gdf_union_merge_allstores] = \\\n",
    "        gen_gdf_all_stores(df=gdf_concat_allstores, gdf_census=gdf_census,l_groupby=['BL','State'])\n",
    "    fg_merged_allstores_region = folium.FeatureGroup(name=f'Region [{region_values['region_no']}/{region_values['region_name']}] \\\n",
    "                                                     Stores[{gdf_union_merge_allstores['num_stores'].values[0]}]',\n",
    "                                                     show=False)\n",
    "    gjson_store = f_maps.get_folium_geojson(gdf_union_merge_allstores.to_crs(4326),\n",
    "                                    fields=['num_stores','area', 'perc_area', 'EWZ', 'perc_pop'],\n",
    "                                    aliases = ['# Stores','Area [Km2]', 'Area perc[%]', 'Pop[M]', 'Pop perc[%]'],\n",
    "                                    is_styled = True,\n",
    "                                    fill_color = merged_stores_color\n",
    "                                    ).add_to(fg_merged_allstores_region)\n",
    "\n",
    "    # l_fg_merged_allstores.append(gdf_union_int_allstores)\n",
    "    l_fg_merged_allstores.append(fg_merged_allstores_region)\n",
    "    d_stores_merged[region_no] ={\n",
    "        'gdf_concat'      : gdf_concat_allstores,\n",
    "        'gdf_union_int'   : gdf_union_int_allstores,\n",
    "        'gdf_union_merge' : gdf_union_merge_allstores,\n",
    "    }\n",
    "\n",
    "if not gdf_concat_allstores.empty:\n",
    "    ### GENERATING GroupedLayerControl FOR REGION ###\n",
    "    fglc_all_stores = folium.plugins.GroupedLayerControl(\n",
    "        groups={f'Regions [{len(d_stores.items())}]': l_fg_merged_allstores},\n",
    "        exclusive_groups=False,\n",
    "        collapsed=False,\n",
    "    )\n",
    "    d_stores_merged['l_fg'] = l_fg_merged_allstores\n",
    "    d_stores_merged['fglc'] = fglc_all_stores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 PoI x Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_stores_logo = {\n",
    "    'sportscheck' : 'assets/SportScheck/1_Home/logo.png',\n",
    "    'decathlon'   : 'assets/Decathlon/1_Home/Decathlon_Logo.jpg',\n",
    "    'intersport'  : 'assets/Intersport/1_Home/logo.jpg'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_store_markers(pdf:pd.DataFrame, l_popup_rows:list,\n",
    "                      name:str, is_shown:bool=False) -> folium.FeatureGroup:\n",
    "    fg = folium.FeatureGroup(name=name, \n",
    "                            show=is_shown)\n",
    "    # Add markers to the map for each point in the DataFrame\n",
    "    for idx, row in pdf.iterrows():\n",
    "        if l_popup_rows:\n",
    "            # Generate HTML content for the popup\n",
    "            html_content = ''\n",
    "            for item in l_popup_rows:\n",
    "                html_row = f'<b>{item}:</b>{row[item]}<br>'\n",
    "                html_content += html_row\n",
    "            popup = folium.Popup(html_content, max_width=250)\n",
    "            print(f'store=[{row['store']}]')\n",
    "            folium.Marker(\n",
    "                location=[row['lat'], row['lon']],\n",
    "                popup=popup,\n",
    "                icon=folium.features.CustomIcon(icon_image=d_stores_logo[row['store']],\n",
    "                                                                icon_size=(50, 15)\n",
    "                                                                ),\n",
    "                tooltip=row['name']\n",
    "            ).add_to(fg)\n",
    "        else:\n",
    "            \n",
    "            folium.Marker(\n",
    "                location=[row['lat'], row['lon']],\n",
    "                popup=f'url=<a href={row['url']}>{row['url']}</a>',\n",
    "                icon=folium.features.CustomIcon(icon_image=d_stores_logo[row['store']],\n",
    "                                                                icon_size=(50, 15)\n",
    "                                                                ),\n",
    "                tooltip=row['name']\n",
    "            ).add_to(fg)\n",
    "    return fg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[sportscheck]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[sportscheck]\n",
      "store=[sportscheck]\n",
      "store=[sportscheck]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[decathlon]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n",
      "store=[intersport]\n"
     ]
    }
   ],
   "source": [
    "l_fg_poi_stores = []\n",
    "if maps_stores_is_pois and bool(d_poi['d_gdf']):\n",
    "    l_cols_poi = list(d_poi['d_gdf'].keys())\n",
    "    for poi,gdf_poi in d_poi['d_gdf'].items():\n",
    "        # print(f'poi={poi}')\n",
    "        gdf_poi = gdf_circles[gdf_circles[poi] > 0]\n",
    "        fg_mk_stores_poi = get_store_markers(pdf=gdf_poi, l_popup_rows=[poi], name=f'[{gdf_poi.shape[0]}] STORES with {poi}')#, is_logging=True)\n",
    "        l_fg_poi_stores += [fg_mk_stores_poi]\n",
    "\n",
    "\n",
    "### ADDING FG into GroupedLayerControl\n",
    "fglc_poi_stores = folium.plugins.GroupedLayerControl(\n",
    "    groups={'PoI Stores': l_fg_poi_stores},\n",
    "    exclusive_groups=False,\n",
    "    collapsed=False,\n",
    ")\n",
    "d_poi_stores = {\n",
    "    'l_fg' : l_fg_poi_stores,\n",
    "    'fglc' : fglc_poi_stores\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 3.1. RoI (Region, Towns, Stores) \n",
      "  Adding RoI [1/5]\n",
      "  Adding RoI [2/5]\n",
      "  Adding RoI [3/5]\n",
      "  Adding RoI [4/5]\n",
      "  Adding RoI [5/5]\n",
      "# 3.2. Points of Interest (Mountains, Campings, Climbs)\n",
      "  Adding PoI [1/6]\n",
      "  Adding PoI [2/6]\n",
      "  Adding PoI [3/6]\n",
      "  Adding PoI [4/6]\n",
      "  Adding PoI [5/6]\n",
      "  Adding PoI [6/6]\n",
      "# 3.3. REGIONS/STORES (Markers, Circles)\n",
      "Region: 09\n",
      "  Store=decathlon\n",
      "  Store=intersport\n",
      "Region: 08\n",
      "  Store=sportscheck\n",
      "  Store=decathlon\n",
      "  Store=intersport\n",
      "  Adding PoI [1/3]\n",
      "  Adding PoI [2/3]\n",
      "  Adding PoI [3/3]\n",
      "Adding Legend...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fullscreen\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<folium.plugins.fullscreen.Fullscreen at 0x17e99661520>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## `m`, folium.Map() ##\n",
    "\n",
    "import folium\n",
    "m=folium.Map()\n",
    "\n",
    "# 3.1. RoI (Region, Towns, Stores) \n",
    "print(f'# 3.1. RoI (Region, Towns, Stores) ')\n",
    "if bool(d_roi):  ## CHeck that the dict is NOT empty\n",
    "    for i,fg in enumerate(d_roi['l_fg']):\n",
    "        print(f'  Adding RoI [{i+1}/{len(d_roi[\"l_fg\"])}]')\n",
    "        fg.add_to(m)\n",
    "    d_roi['fglc'].add_to(m)\n",
    "\n",
    "\n",
    "# 3.2. d_poi (Point of Interests)\n",
    "print('# 3.2. Points of Interest (Mountains, Campings, Climbs)')\n",
    "if bool(d_poi):  ## CHeck that the dict is NOT empty\n",
    "    for i,fg in enumerate(d_poi['l_fg']):\n",
    "        print(f'  Adding PoI [{i+1}/{len(d_poi[\"l_fg\"])}]')\n",
    "        fg.add_to(m)\n",
    "    d_poi['fglc'].add_to(m)\n",
    "\n",
    "# 3.3. REGIONS/STORES\n",
    "print('# 3.3. REGIONS/STORES (Markers, Circles)')\n",
    "if bool(d_stores):  ## CHeck that the dict is NOT empty\n",
    "    for k,v in d_stores.items():\n",
    "        print(f'Region: {k}')\n",
    "        for s,v in v['store'].items():\n",
    "            print(f'  Store={s}')\n",
    "            for fg in v['l_children']:\n",
    "                fg.add_to(m)\n",
    "            v['fglc'].add_to(m)\n",
    "\n",
    "# # 3.4. GROUPED REGIONS/STORES\n",
    "# # print('# 3.4. GROUPED REGIONS/STORES')\n",
    "# print('# 3.4. GROUPED REGIONS/STORES')\n",
    "# if bool(d_stores_merged):  ## CHeck that the dict is NOT empty\n",
    "#     for fg in d_stores_merged['l_fg']:\n",
    "#         fg.add_to(m)\n",
    "#     d_stores_merged['fglc'].add_to(m)\n",
    "\n",
    "if bool(d_poi_stores):\n",
    "    for i,fg in enumerate(d_poi_stores['l_fg']):\n",
    "        print(f'  Adding PoI [{i+1}/{len(d_poi_stores[\"l_fg\"])}]')\n",
    "        fg.add_to(m)\n",
    "    d_poi_stores['fglc'].add_to(m)\n",
    "    \n",
    "    \n",
    "folium.LayerControl(position='topright',collapsed=False).add_to(m)\n",
    "print('Adding Legend...')\n",
    "m.fit_bounds(m.get_bounds())\n",
    "print('Adding fullscreen')\n",
    "\n",
    "folium.plugins.Fullscreen(position='topleft',\n",
    "                        title='Expand me',\n",
    "                        title_cancel='Exit me',\n",
    "                        force_separate_button=True).add_to(m)\n",
    "\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('./34.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### VALIDATION ###\n",
    "# print(f'Inside ={ num_inside_towns}')\n",
    "# print(f'Partly ={num_partly_towns}')\n",
    "# print(f'Outside ={num_outside_towns}')\n",
    "# print(f'Inside+Partly={num_inside_towns+ num_partly_towns}')\n",
    "# print(f'Total intersection={gdf_dist.shape[0]}')\n",
    "\n",
    "# print(f'Inside+Partly+Outside={num_inside_towns+ num_partly_towns+num_outside_towns}')\n",
    "# print(f'Total Geom ={gdf_census.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.save('./bw_by_decathlon_sportscheck_intersport.html')\n",
    "# gdf_merge_concat.to_file('./gdf_sued_germany2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO BE MOVED TO STORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. NEW CODE -> GEOM+STORES (Intersections,Merges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature group Intersection (`fg_int_circ_geom` using `gdf_int_circ_geom`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gdf_store_circles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[110], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m gdf_int_circ_geom \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39moverlay(gdf_census\u001b[38;5;241m.\u001b[39mto_crs(epsg\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6933\u001b[39m), \n\u001b[1;32m----> 2\u001b[0m                                 \u001b[43mgdf_store_circles\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeometry\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstore_name\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_crs(\u001b[38;5;241m6933\u001b[39m), \n\u001b[0;32m      3\u001b[0m                                 how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintersection\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gdf_store_circles' is not defined"
     ]
    }
   ],
   "source": [
    "gdf_int_circ_geom = gpd.overlay(gdf_census.to_crs(epsg=6933), \n",
    "                                gdf_store_circles[['geometry','store','store_name']].to_crs(6933), \n",
    "                                how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x1a84ddb7fb0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_int_circ_geom = folium.FeatureGroup('overlay')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_int_circ_geom,#.to_crs(4326), \n",
    "                        fields=['GEN','store_name', 'EWZ', 'KFL'],\n",
    "                        aliases = ['Location','store_name', 'Pop', 'Area_dbms'])\n",
    "gjson_store.add_to(fg_int_circ_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature group Merge (`fg_mer_circ_geom` using `gdf_mer_circ_geom`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_mer_circ_geom = gdf_int_circ_geom.groupby(['store','store_name']).agg( \\\n",
    "        {'geometry': lambda x: x.geometry.union_all(),\n",
    "        'EWZ':'sum', \n",
    "        'KFL' : 'sum',\n",
    "        }).set_geometry(\"geometry\").set_crs(6933).reset_index()\n",
    "gdf_mer_circ_geom['area_geom'] = gdf_mer_circ_geom.geometry.area / 10**6\n",
    "# gdf_me.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x1a832cd3590>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_mer_circ_geom = folium.FeatureGroup('merge')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_mer_circ_geom.to_crs(4326),\n",
    "                        fields=['store', 'store_name', 'EWZ', 'area_geom', 'KFL'],\n",
    "                        aliases = ['store','store_name', 'Pop', 'Area_geom[Km2]', 'Area_dbms[Km2]'])\n",
    "gjson_store.add_to(fg_mer_circ_geom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5.OLD CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group Circles (`fg_circ` using `gdf_store_circles`)\n",
    "[`pdf_stores` and `radius_km`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x204fa0521e0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math, folium\n",
    "\n",
    "gdf_store_circles = f_maps.get_gdf_circle(df=pdf_stores, radius_km= radius_km)\n",
    "# gdf_store_circles.shape\n",
    "\n",
    "fg_roi_area = gdf_census_merged.area_geom.sum()\n",
    "num_stores = gdf_store_circles.shape[0]\n",
    "area_circ  = round(math.pi * radius_km**2, round_dec)\n",
    "area_total = round(num_stores*area_circ, round_dec)\n",
    "perc_area  = round(area_total/fg_roi_area, round_dec)\n",
    "\n",
    "str_legend = f'[# Circles={num_stores}, radius={radius_km}Km, ' \\\n",
    "             f'area circle={area_circ}Km2, ' \\\n",
    "             f'area total ={area_total}Km2, ' \\\n",
    "             f'perc_area = {perc_area}]'\n",
    "# str_legend\n",
    "fg_circ_store = folium.FeatureGroup(name=f'Circles {str_legend}')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_store_circles, \n",
    "                                fields=['store','name', 'address'],\n",
    "                                # aliases = ['Shop']\n",
    "                                )\n",
    "gjson_store.add_to(fg_circ_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Featour Group Circles union (`fg_circ_union`) -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group Circles (`fg_circ_merged` using `gdf_store_circles_merged`)\n",
    "[`pdf_stores` and `radius_km`])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x204886807d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_merged = gdf_store_circles.geometry.union_all()\n",
    "gdf_store_circles_merged = gpd.GeoSeries([poly_merged]).to_frame(name='geometry').set_crs(epsg=4326)\n",
    "num_stores = gdf_store_circles.shape[0]\n",
    "area_total = round(gdf_store_circles_merged.to_crs(6933).geometry.area.sum() / 10**6, round_dec)\n",
    "perc_area  = round(area_total/fg_roi_area, round_dec)\n",
    "\n",
    "\n",
    "str_legend = f'[# Stores={num_stores},' \\\n",
    "             f'area ={area_total}Km2, ' \\\n",
    "             f'perc_area = {perc_area}]'\n",
    "\n",
    "gdf_store_circles_merged['num_stores'] = num_stores\n",
    "gdf_store_circles_merged['area'] = area_total\n",
    "gdf_store_circles_merged['perc_area'] = perc_area\n",
    "\n",
    "\n",
    "fg_circ_merged = folium.FeatureGroup(name=f'Circles Merged {str_legend}')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_store_circles_merged, \n",
    "                                fields=['num_stores','area', 'perc_area'],\n",
    "                                aliases = ['# Stores','Area [Km2]', 'Percentage'],\n",
    "                                is_styled = True\n",
    "                                )\n",
    "gjson_store.add_to(fg_circ_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group MERGE (`fg_merge` using [`gdf_intersection`, `gdf_overlay`])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ('centroid' in gdf_census_region.columns):\n",
    "    gdf_census_region = gdf_census_region.drop(columns=['centroid'])\n",
    "\n",
    "col_perc_dbms = 'PERC_dbms_int'\n",
    "col_perc_geom = 'PERC_roi_int'\n",
    "col_perc_pop = 'PERC_pop'\n",
    "l_cols_percentaged = ['area_geom', 'EWZ', 'KFL']\n",
    "\n",
    "d_columns = {\n",
    "    'area_geom':{'alias' : 'area',        'is_norm': True,  'is_int':False},\n",
    "    'KFL':     {'alias' : 'area_data',    'is_norm': True,  'is_int':False},\n",
    "    'EWZ':     {'alias' : 'Population',   'is_norm': True,  'is_int':True}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "area_geom = 3254.19\n",
      "area_geom_int = 2221.0\n",
      "EWZ = 3051459\n",
      "EWZ_int = 2441322\n",
      "KFL = 3199\n",
      "KFL_int = 2181.25\n",
      "perc_data = 0.68\n",
      "perc_geom = 0.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x22d81f86690>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# OVERLAY / individual ####################\n",
    "\n",
    "# Set the column used for NORMALIZATION (denominator)\n",
    "gdf_intersection = gpd.overlay(gdf_census_region, gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_intersection = gdf_intersection.drop_duplicates()\n",
    "gdf_intersection['area'] = round(gdf_intersection['geometry'].area / 10**6, 2)\n",
    "gdf_intersection[col_perc_geom] = gdf_intersection['area'] / gdf_intersection['area_geom']\n",
    "\n",
    "# Generate Overlay with the intersection and drop duplicates\n",
    "gdf_overlay = f_maps.overlay_shapes(gdf_circle=gdf_intersection,\n",
    "                                    col_perc=col_perc_geom, \n",
    "                                    d_columns=d_columns)\n",
    "gdf_overlay_dd = gdf_overlay.drop_duplicates(subset=['OBJID'])\n",
    "\n",
    "# Merge Overlay\n",
    "gdf_merge = f_maps.merge_shapes(gdf_intersection, l_col_percs=l_cols_percentaged,\n",
    "                                d_percs={'data':'KFL', 'geom':'area_geom'}, \n",
    "                                num_dec=round_dec, is_logging=True)\n",
    "gdf_merge = gdf_merge.drop_duplicates()\n",
    "\n",
    "\n",
    "total_area_geom = round(gdf_census_region.geometry.area.sum() / 10**6, round_dec)\n",
    "total_area_pop = round(gdf_census_region.EWZ.sum() / 10**6, round_dec)\n",
    "# merge_area_dbms = round(gdf_census_region.KFL.sum(), round_dec)\n",
    "# merge_area_circ = round(gdf_store_circles_merged.to_crs(6933).geometry.area.sum() / 10**6, round_dec)\n",
    "merge_area_inside = round(gdf_intersection[\"area\"].sum() , round_dec)\n",
    "perc_area_inside  = round(merge_area_inside/total_area_geom, round_dec)\n",
    "pop_inside =  round(gdf_merge.EWZ_int.sum() / 10**6, round_dec)\n",
    "pop_total =  round(gdf_merge.EWZ.sum() / 10**6, round_dec)\n",
    "perc_pop = round(pop_inside/total_area_pop, round_dec)\n",
    "\n",
    "\n",
    "gdf_merge['EWZ'] = gdf_merge.EWZ.sum()\n",
    "gdf_merge['KFL'] = gdf_merge.KFL.sum()\n",
    "\n",
    "# area_dbms={merge_area_dbms}Km2,  \\\n",
    "# area_circ_merged={merge_area_circ}Km2, \\\n",
    "msg_merge = f'area_int={merge_area_inside}Km2, \\\n",
    "              total_area_geom={total_area_geom}Km2,  \\\n",
    "              perc_area={perc_area_inside}, \\\n",
    "              Pop_inside={pop_inside}M,  \\\n",
    "              Pop_total={total_area_pop}M, \\\n",
    "              perc_pop={perc_pop} '\n",
    "\n",
    "\n",
    "fg_merge = folium.FeatureGroup(name=f'Merge (Geom, Circles) [{msg_merge}]')\n",
    "\n",
    "# gdf_merge['num_in'] = gdf_inside.shape[0]\n",
    "# gdf_merge['num_part'] = gdf_partly.shape[0]\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_merge, \n",
    "                                  fields=[\n",
    "                                    # 'KFL_int', 'KFL', 'perc_data', \n",
    "                                    'area_roi_int', 'area_geom', 'perc_geom',\n",
    "                                    'EWZ_int', 'EWZ',\n",
    "                                    # 'num_in', 'num_part', \n",
    "                                    ],\n",
    "                                  aliases = [\n",
    "                                    # 'Area_dbms intersection [Km2]', 'Area_dbms shape [Km2]','Percentage dbms', \n",
    "                                    'Area_geom intersection [Km2]', 'Area_geom shape [Km2]','Percentage geometry',\n",
    "                                    'Population intersection', 'Population shape',\n",
    "                                    # '# Localities inside', \n",
    "                                    # '# Localities partially inside',\n",
    "                                    ])\n",
    "gjson_store.add_to(fg_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJID</th>\n",
       "      <th>ADE</th>\n",
       "      <th>GF</th>\n",
       "      <th>BSG</th>\n",
       "      <th>ARS</th>\n",
       "      <th>AGS</th>\n",
       "      <th>SDV_ARS</th>\n",
       "      <th>GEN</th>\n",
       "      <th>BEZ</th>\n",
       "      <th>IBZ</th>\n",
       "      <th>BEM</th>\n",
       "      <th>NBD</th>\n",
       "      <th>SN_L</th>\n",
       "      <th>SN_R</th>\n",
       "      <th>SN_K</th>\n",
       "      <th>SN_V1</th>\n",
       "      <th>SN_V2</th>\n",
       "      <th>SN_G</th>\n",
       "      <th>FK_S3</th>\n",
       "      <th>NUTS</th>\n",
       "      <th>ARS_0</th>\n",
       "      <th>AGS_0</th>\n",
       "      <th>EWZ</th>\n",
       "      <th>KFL</th>\n",
       "      <th>DLM_ID</th>\n",
       "      <th>EPK</th>\n",
       "      <th>EPK_norm</th>\n",
       "      <th>KFL_GPD</th>\n",
       "      <th>area_geom</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>num_stores</th>\n",
       "      <th>area</th>\n",
       "      <th>perc_area</th>\n",
       "      <th>geometry</th>\n",
       "      <th>PERC_geom_int</th>\n",
       "      <th>area_geom_int</th>\n",
       "      <th>KFL_int</th>\n",
       "      <th>EWZ_int</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEBKGVG20000040K</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>081110000000</td>\n",
       "      <td>08111000</td>\n",
       "      <td>081110000000</td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>60</td>\n",
       "      <td>kreisfrei</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>00</td>\n",
       "      <td>00</td>\n",
       "      <td>000</td>\n",
       "      <td>R</td>\n",
       "      <td>DE111</td>\n",
       "      <td>081110000000</td>\n",
       "      <td>08111000</td>\n",
       "      <td>632865</td>\n",
       "      <td>207</td>\n",
       "      <td>DEBKGDL20000DZKQ</td>\n",
       "      <td>3057.318841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.95</td>\n",
       "      <td>209.95</td>\n",
       "      <td>48.774528</td>\n",
       "      <td>9.172003</td>\n",
       "      <td>14</td>\n",
       "      <td>209.95</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((890086.186 5519140.548, 890062.887 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>209.95</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>632865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEBKGVG20000040L</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>081150003003</td>\n",
       "      <td>08115003</td>\n",
       "      <td>081150003003</td>\n",
       "      <td>Böblingen</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>61</td>\n",
       "      <td>--</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00</td>\n",
       "      <td>03</td>\n",
       "      <td>003</td>\n",
       "      <td>R</td>\n",
       "      <td>DE112</td>\n",
       "      <td>081150003003</td>\n",
       "      <td>08115003</td>\n",
       "      <td>51460</td>\n",
       "      <td>39</td>\n",
       "      <td>DEBKGDL20000DZZJ</td>\n",
       "      <td>1319.487179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.85</td>\n",
       "      <td>38.85</td>\n",
       "      <td>48.681829</td>\n",
       "      <td>9.019745</td>\n",
       "      <td>14</td>\n",
       "      <td>38.85</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((873632.552 5505373.157, 873816.137 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.85</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>51460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEBKGVG20000040M</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>081150028028</td>\n",
       "      <td>08115028</td>\n",
       "      <td>081150028028</td>\n",
       "      <td>Leonberg</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>61</td>\n",
       "      <td>--</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00</td>\n",
       "      <td>28</td>\n",
       "      <td>028</td>\n",
       "      <td>R</td>\n",
       "      <td>DE112</td>\n",
       "      <td>081150028028</td>\n",
       "      <td>08115028</td>\n",
       "      <td>49512</td>\n",
       "      <td>48</td>\n",
       "      <td>DEBKGDL20000E4K3</td>\n",
       "      <td>1031.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.93</td>\n",
       "      <td>48.93</td>\n",
       "      <td>48.790222</td>\n",
       "      <td>9.007016</td>\n",
       "      <td>14</td>\n",
       "      <td>48.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((867937.043 5516393.419, 868155.837 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.93</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>49512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEBKGVG20000040N</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>081150029029</td>\n",
       "      <td>08115029</td>\n",
       "      <td>081150029029</td>\n",
       "      <td>Magstadt</td>\n",
       "      <td>Gemeinde</td>\n",
       "      <td>62</td>\n",
       "      <td>--</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00</td>\n",
       "      <td>29</td>\n",
       "      <td>029</td>\n",
       "      <td>R</td>\n",
       "      <td>DE112</td>\n",
       "      <td>081150029029</td>\n",
       "      <td>08115029</td>\n",
       "      <td>9789</td>\n",
       "      <td>19</td>\n",
       "      <td>DEBKGDL20000E25V</td>\n",
       "      <td>515.210526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.18</td>\n",
       "      <td>19.18</td>\n",
       "      <td>48.744854</td>\n",
       "      <td>8.979303</td>\n",
       "      <td>14</td>\n",
       "      <td>19.18</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((865068.904 5510504.873, 865165.707 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.18</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEBKGVG20000040O</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>081150041041</td>\n",
       "      <td>08115041</td>\n",
       "      <td>081150041041</td>\n",
       "      <td>Renningen</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>61</td>\n",
       "      <td>--</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>00</td>\n",
       "      <td>41</td>\n",
       "      <td>041</td>\n",
       "      <td>R</td>\n",
       "      <td>DE112</td>\n",
       "      <td>081150041041</td>\n",
       "      <td>08115041</td>\n",
       "      <td>18596</td>\n",
       "      <td>31</td>\n",
       "      <td>DEBKGDL20000E25W</td>\n",
       "      <td>599.870968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.93</td>\n",
       "      <td>30.93</td>\n",
       "      <td>48.772198</td>\n",
       "      <td>8.924277</td>\n",
       "      <td>14</td>\n",
       "      <td>30.93</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((860949.389 5513523.328, 861293.374 5...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.93</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>18596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>DEBKGVG2000004S9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>084265005028</td>\n",
       "      <td>08426028</td>\n",
       "      <td>084265005028</td>\n",
       "      <td>Burgrieden</td>\n",
       "      <td>Gemeinde</td>\n",
       "      <td>64</td>\n",
       "      <td>gemeinschaftsangehörig</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>05</td>\n",
       "      <td>028</td>\n",
       "      <td>R</td>\n",
       "      <td>DE146</td>\n",
       "      <td>084265005028</td>\n",
       "      <td>08426028</td>\n",
       "      <td>4255</td>\n",
       "      <td>21</td>\n",
       "      <td>DEBKGDL20000DWQK</td>\n",
       "      <td>202.619048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.85</td>\n",
       "      <td>21.85</td>\n",
       "      <td>48.231287</td>\n",
       "      <td>9.950261</td>\n",
       "      <td>14</td>\n",
       "      <td>17.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((960372.47 5466782.257, 960485.561 54...</td>\n",
       "      <td>0.810984</td>\n",
       "      <td>17.72</td>\n",
       "      <td>17.030664</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>DEBKGVG2000004SA</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>084265005070</td>\n",
       "      <td>08426070</td>\n",
       "      <td>084265005070</td>\n",
       "      <td>Laupheim</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>63</td>\n",
       "      <td>gemeinschaftsangehörig</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>05</td>\n",
       "      <td>070</td>\n",
       "      <td>R</td>\n",
       "      <td>DE146</td>\n",
       "      <td>084265005070</td>\n",
       "      <td>08426070</td>\n",
       "      <td>22863</td>\n",
       "      <td>61</td>\n",
       "      <td>DEBKGDL20000DWYR</td>\n",
       "      <td>374.803279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.84</td>\n",
       "      <td>61.84</td>\n",
       "      <td>48.227640</td>\n",
       "      <td>9.864039</td>\n",
       "      <td>14</td>\n",
       "      <td>19.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>MULTIPOLYGON (((960809.78 5468401.469, 960795....</td>\n",
       "      <td>0.323254</td>\n",
       "      <td>19.99</td>\n",
       "      <td>19.718467</td>\n",
       "      <td>7390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>DEBKGVG2000004SP</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>084265009108</td>\n",
       "      <td>08426108</td>\n",
       "      <td>084265009108</td>\n",
       "      <td>Schwendi</td>\n",
       "      <td>Gemeinde</td>\n",
       "      <td>64</td>\n",
       "      <td>gemeinschaftsangehörig</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>09</td>\n",
       "      <td>108</td>\n",
       "      <td>R</td>\n",
       "      <td>DE146</td>\n",
       "      <td>084265009108</td>\n",
       "      <td>08426108</td>\n",
       "      <td>7061</td>\n",
       "      <td>49</td>\n",
       "      <td>DEBKGDL20000E1X1</td>\n",
       "      <td>144.102041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.14</td>\n",
       "      <td>49.14</td>\n",
       "      <td>48.190639</td>\n",
       "      <td>9.978345</td>\n",
       "      <td>14</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((966179.863 5466325.021, 966102.261 5...</td>\n",
       "      <td>0.088523</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.337607</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>DEBKGVG2000004TC</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>084355007053</td>\n",
       "      <td>08435053</td>\n",
       "      <td>084355007053</td>\n",
       "      <td>Sipplingen</td>\n",
       "      <td>Gemeinde</td>\n",
       "      <td>64</td>\n",
       "      <td>gemeinschaftsangehörig</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>07</td>\n",
       "      <td>053</td>\n",
       "      <td>R</td>\n",
       "      <td>DE147</td>\n",
       "      <td>084355007053</td>\n",
       "      <td>08435053</td>\n",
       "      <td>2189</td>\n",
       "      <td>4</td>\n",
       "      <td>DEBKGDL20000E59B</td>\n",
       "      <td>547.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4.44</td>\n",
       "      <td>47.798317</td>\n",
       "      <td>9.102492</td>\n",
       "      <td>14</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((876694.109 5428537.967, 877066.744 5...</td>\n",
       "      <td>0.466216</td>\n",
       "      <td>2.07</td>\n",
       "      <td>1.864865</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>DEBKGVG2000004TD</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>084355007059</td>\n",
       "      <td>08435059</td>\n",
       "      <td>084355007059</td>\n",
       "      <td>Überlingen</td>\n",
       "      <td>Stadt</td>\n",
       "      <td>63</td>\n",
       "      <td>gemeinschaftsangehörig</td>\n",
       "      <td>ja</td>\n",
       "      <td>08</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>50</td>\n",
       "      <td>07</td>\n",
       "      <td>059</td>\n",
       "      <td>R</td>\n",
       "      <td>DE147</td>\n",
       "      <td>084355007059</td>\n",
       "      <td>08435059</td>\n",
       "      <td>23098</td>\n",
       "      <td>58</td>\n",
       "      <td>DEBKGDL20000E4ZZ</td>\n",
       "      <td>398.241379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.84</td>\n",
       "      <td>58.84</td>\n",
       "      <td>47.796793</td>\n",
       "      <td>9.161327</td>\n",
       "      <td>14</td>\n",
       "      <td>4.72</td>\n",
       "      <td>0.39</td>\n",
       "      <td>POLYGON ((877916.131 5428649.829, 877555.459 5...</td>\n",
       "      <td>0.080218</td>\n",
       "      <td>4.72</td>\n",
       "      <td>4.652617</td>\n",
       "      <td>1852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                OBJID  ADE  GF  BSG           ARS       AGS       SDV_ARS  \\\n",
       "0    DEBKGVG20000040K    6   4    1  081110000000  08111000  081110000000   \n",
       "1    DEBKGVG20000040L    6   4    1  081150003003  08115003  081150003003   \n",
       "2    DEBKGVG20000040M    6   4    1  081150028028  08115028  081150028028   \n",
       "3    DEBKGVG20000040N    6   4    1  081150029029  08115029  081150029029   \n",
       "4    DEBKGVG20000040O    6   4    1  081150041041  08115041  081150041041   \n",
       "..                ...  ...  ..  ...           ...       ...           ...   \n",
       "533  DEBKGVG2000004S9    6   4    1  084265005028  08426028  084265005028   \n",
       "534  DEBKGVG2000004SA    6   4    1  084265005070  08426070  084265005070   \n",
       "535  DEBKGVG2000004SP    6   4    1  084265009108  08426108  084265009108   \n",
       "536  DEBKGVG2000004TC    6   4    1  084355007053  08435053  084355007053   \n",
       "537  DEBKGVG2000004TD    6   4    1  084355007059  08435059  084355007059   \n",
       "\n",
       "            GEN       BEZ  IBZ                     BEM NBD SN_L SN_R SN_K  \\\n",
       "0     Stuttgart     Stadt   60               kreisfrei  ja   08    1   11   \n",
       "1     Böblingen     Stadt   61                      --  ja   08    1   15   \n",
       "2      Leonberg     Stadt   61                      --  ja   08    1   15   \n",
       "3      Magstadt  Gemeinde   62                      --  ja   08    1   15   \n",
       "4     Renningen     Stadt   61                      --  ja   08    1   15   \n",
       "..          ...       ...  ...                     ...  ..  ...  ...  ...   \n",
       "533  Burgrieden  Gemeinde   64  gemeinschaftsangehörig  ja   08    4   26   \n",
       "534    Laupheim     Stadt   63  gemeinschaftsangehörig  ja   08    4   26   \n",
       "535    Schwendi  Gemeinde   64  gemeinschaftsangehörig  ja   08    4   26   \n",
       "536  Sipplingen  Gemeinde   64  gemeinschaftsangehörig  ja   08    4   35   \n",
       "537  Überlingen     Stadt   63  gemeinschaftsangehörig  ja   08    4   35   \n",
       "\n",
       "    SN_V1 SN_V2 SN_G FK_S3   NUTS         ARS_0     AGS_0     EWZ  KFL  \\\n",
       "0      00    00  000     R  DE111  081110000000  08111000  632865  207   \n",
       "1      00    03  003     R  DE112  081150003003  08115003   51460   39   \n",
       "2      00    28  028     R  DE112  081150028028  08115028   49512   48   \n",
       "3      00    29  029     R  DE112  081150029029  08115029    9789   19   \n",
       "4      00    41  041     R  DE112  081150041041  08115041   18596   31   \n",
       "..    ...   ...  ...   ...    ...           ...       ...     ...  ...   \n",
       "533    50    05  028     R  DE146  084265005028  08426028    4255   21   \n",
       "534    50    05  070     R  DE146  084265005070  08426070   22863   61   \n",
       "535    50    09  108     R  DE146  084265009108  08426108    7061   49   \n",
       "536    50    07  053     R  DE147  084355007053  08435053    2189    4   \n",
       "537    50    07  059     R  DE147  084355007059  08435059   23098   58   \n",
       "\n",
       "               DLM_ID          EPK  EPK_norm  KFL_GPD  area_geom        lat  \\\n",
       "0    DEBKGDL20000DZKQ  3057.318841       0.0   209.95     209.95  48.774528   \n",
       "1    DEBKGDL20000DZZJ  1319.487179       0.0    38.85      38.85  48.681829   \n",
       "2    DEBKGDL20000E4K3  1031.500000       0.0    48.93      48.93  48.790222   \n",
       "3    DEBKGDL20000E25V   515.210526       0.0    19.18      19.18  48.744854   \n",
       "4    DEBKGDL20000E25W   599.870968       0.0    30.93      30.93  48.772198   \n",
       "..                ...          ...       ...      ...        ...        ...   \n",
       "533  DEBKGDL20000DWQK   202.619048       0.0    21.85      21.85  48.231287   \n",
       "534  DEBKGDL20000DWYR   374.803279       0.0    61.84      61.84  48.227640   \n",
       "535  DEBKGDL20000E1X1   144.102041       0.0    49.14      49.14  48.190639   \n",
       "536  DEBKGDL20000E59B   547.250000       0.0     4.44       4.44  47.798317   \n",
       "537  DEBKGDL20000E4ZZ   398.241379       0.0    58.84      58.84  47.796793   \n",
       "\n",
       "          lon  num_stores    area  perc_area  \\\n",
       "0    9.172003          14  209.95       0.39   \n",
       "1    9.019745          14   38.85       0.39   \n",
       "2    9.007016          14   48.93       0.39   \n",
       "3    8.979303          14   19.18       0.39   \n",
       "4    8.924277          14   30.93       0.39   \n",
       "..        ...         ...     ...        ...   \n",
       "533  9.950261          14   17.72       0.39   \n",
       "534  9.864039          14   19.99       0.39   \n",
       "535  9.978345          14    4.35       0.39   \n",
       "536  9.102492          14    2.07       0.39   \n",
       "537  9.161327          14    4.72       0.39   \n",
       "\n",
       "                                              geometry  PERC_geom_int  \\\n",
       "0    POLYGON ((890086.186 5519140.548, 890062.887 5...       1.000000   \n",
       "1    POLYGON ((873632.552 5505373.157, 873816.137 5...       1.000000   \n",
       "2    POLYGON ((867937.043 5516393.419, 868155.837 5...       1.000000   \n",
       "3    POLYGON ((865068.904 5510504.873, 865165.707 5...       1.000000   \n",
       "4    POLYGON ((860949.389 5513523.328, 861293.374 5...       1.000000   \n",
       "..                                                 ...            ...   \n",
       "533  POLYGON ((960372.47 5466782.257, 960485.561 54...       0.810984   \n",
       "534  MULTIPOLYGON (((960809.78 5468401.469, 960795....       0.323254   \n",
       "535  POLYGON ((966179.863 5466325.021, 966102.261 5...       0.088523   \n",
       "536  POLYGON ((876694.109 5428537.967, 877066.744 5...       0.466216   \n",
       "537  POLYGON ((877916.131 5428649.829, 877555.459 5...       0.080218   \n",
       "\n",
       "     area_geom_int     KFL_int  EWZ_int  \n",
       "0           209.95  207.000000   632865  \n",
       "1            38.85   39.000000    51460  \n",
       "2            48.93   48.000000    49512  \n",
       "3            19.18   19.000000     9789  \n",
       "4            30.93   31.000000    18596  \n",
       "..             ...         ...      ...  \n",
       "533          17.72   17.030664     3450  \n",
       "534          19.99   19.718467     7390  \n",
       "535           4.35    4.337607      625  \n",
       "536           2.07    1.864865     1020  \n",
       "537           4.72    4.652617     1852  \n",
       "\n",
       "[538 rows x 39 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf_intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group INDIV (`fg_join_ind` and `fg_merge_ind`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/14] center_point=(49.00488565, 8.449674128073184, 'decathlon_Karlsruhe-Durlach')\n",
      "[2/14] center_point=(48.4007813, 9.9583729, 'decathlon_Ulm')\n",
      "[3/14] center_point=(48.7026898, 9.437392619846309, 'decathlon_Plochingen')\n",
      "[4/14] center_point=(48.7965766, 8.19518157114592, 'decathlon_Baden - Baden')\n",
      "[5/14] center_point=(48.8201891, 10.045626348192611, 'decathlon_Aalen-Essingen')\n",
      "[6/14] center_point=(49.3941626, 8.57783239839136, 'decathlon_Schwetzingen')\n",
      "[7/14] center_point=(48.6882907, 9.0090554, 'decathlon_Böblingen')\n",
      "[8/14] center_point=(47.610891699999996, 7.661843945356753, 'decathlon_Lörrach')\n",
      "[9/14] center_point=(48.900043, 9.1916945, 'decathlon_Ludwigsburg')\n",
      "[10/14] center_point=(49.1460258, 9.2214379, 'decathlon_Heilbronn-K3')\n",
      "[11/14] center_point=(48.472267200000005, 7.944426365060242, 'decathlon_Offenburg')\n",
      "[12/14] center_point=(47.7599556, 8.8420214, 'decathlon_Singen')\n",
      "[13/14] center_point=(48.791258850000006, 9.182104646022687, 'decathlon_Stuttgart-Milaneo')\n",
      "[14/14] center_point=(48.8168724, 9.300342163579177, 'decathlon_Waiblingen')\n"
     ]
    }
   ],
   "source": [
    "fg_join_ind = folium.FeatureGroup(name=f'Individual Join [#Stores={len(l_center_points)}]')\n",
    "fg_merge_ind = folium.FeatureGroup(name=f'Individual Merge [#Stores={len(l_center_points)}]')\n",
    "# gdf_sc_6933 = gdf_store_circles.to_crs(6933)\n",
    "\n",
    "# for i,(index,store) in enumerate(gdf_sc_6933.iterrows()):\n",
    "#     print(f'[{i}/{gdf_store_circles.shape[0]}] Store={store.store}_{store['name']}')\n",
    "\n",
    "for i,center_point in enumerate(l_center_points):\n",
    "    print(f'[{i+1}/{len(l_center_points)}] center_point={center_point}')\n",
    "    lon = center_point[1]\n",
    "    lat = center_point[0]\n",
    "    store_name = center_point[2]\n",
    "\n",
    "    # Convert the Shapely circle to a geoDataFrame\n",
    "    poly_circle = f_maps.circle_latlon(lon=lon, lat=lat, radius=1000 * radius_km)\n",
    "    gdf = gpd.GeoSeries([poly_circle])\n",
    "    gdf_overlay = gdf.to_frame(name='geometry').set_crs(epsg=4326)\n",
    "    gdf_circle_6933 = gdf_overlay.to_crs(epsg=6933)\n",
    "    gdf_overlay = gpd.overlay(gdf_census_region, gdf_circle_6933, how='intersection')\n",
    "\n",
    "    # Set the column used for NORMALIZATION (numerator)\n",
    "    gdf_overlay['area'] = round(gdf_overlay['geometry'].area / 10**6, 3)\n",
    "    gdf_overlay[col_perc_geom] = round(gdf_overlay['area'] / gdf_overlay['area_geom'], 3)\n",
    "    \n",
    "    gdf_overlay = f_maps.overlay_shapes(gdf_circle=gdf_overlay,\n",
    "                                        col_perc=col_perc_geom, \n",
    "                                        d_columns=d_columns)\n",
    "    gdf_overlay = gdf_overlay.drop_duplicates(subset=['OBJID'])\n",
    "    gdf_overlay[col_perc_dbms] = round(gdf_overlay['KFL_int'] / gdf_overlay['KFL'], 3)\n",
    "    gdf_overlay[col_perc_pop] = round(gdf_overlay['EWZ_int'] / gdf_overlay['EWZ'], 3)\n",
    "    gdf_overlay['store_name'] = store_name\n",
    "\n",
    "    gjson_store = f_maps.get_folium_geojson(gdf_overlay,#.to_crs(4326), \n",
    "                                    fields=[\n",
    "                                        'store_name', 'GEN',\n",
    "                                        # 'KFL_int', 'KFL', # col_perc_dbms, \n",
    "                                        'area_roi_int', 'area_geom', col_perc_geom,\n",
    "                                        'EWZ_int', 'EWZ', col_perc_pop,\n",
    "                                        # 'num_in', 'num_part', \n",
    "                                        ],\n",
    "                                    aliases = [\n",
    "                                        'Store', 'City',\n",
    "                                        # 'Area_dbms intersection [Km2]', 'Area_dbms shape [Km2]','Percentage dbms', \n",
    "                                        'Area_geom intersection [Km2]', 'Area_geom shape [Km2]', 'Percentage geometry',\n",
    "                                        'Population inside', 'Population total', 'Percentage population'\n",
    "                                        # 'Localities inside', 'Localities partially inside',\n",
    "                                        ])\n",
    "    gjson_store.add_to(fg_join_ind)\n",
    "\n",
    "    gdf_merge = f_maps.merge_shapes(gdf_overlay, l_col_percs=l_cols_percentaged,\n",
    "                                            d_percs={'data':'KFL', 'geom':'area_geom'}, \n",
    "                                            num_dec=round_dec, is_logging=False)\n",
    "    # Copying Location Identifier\n",
    "    gdf_merge['GEN'] = gdf_overlay['GEN']\n",
    "    # Set the column used for NORMALIZATION (numerator)\n",
    "    gdf_merge['area'] = round(gdf_merge['geometry'].area / 10**6, round_dec)\n",
    "    gdf_merge[col_perc_geom] = round(gdf_merge['area'] / gdf_merge['area_geom'], 3)\n",
    "    gdf_merge[col_perc_dbms] = round(gdf_merge['KFL_int'] / gdf_merge['KFL'], 3)\n",
    "    gdf_merge[col_perc_pop] = round(gdf_merge['EWZ_int'] / gdf_merge['EWZ'], 3)\n",
    "    gdf_merge['store_name'] = store_name\n",
    "    \n",
    "    gjson_store = f_maps.get_folium_geojson(gdf_merge,#.to_crs(4326), \n",
    "                            fields=[\n",
    "                                'store_name',\n",
    "                                # 'KFL_int', 'KFL', col_perc_dbms,\n",
    "                                'area_roi_int', 'area_geom', col_perc_geom,\n",
    "                                'EWZ_int', 'EWZ', col_perc_pop,\n",
    "                                # 'num_in', 'num_part', \n",
    "                                ],\n",
    "                            aliases = [\n",
    "                                'Location',\n",
    "                                # 'Area_dbms intersection [Km2]', 'Area_dbms shape [Km2]', 'Percentage dbms', \n",
    "                                'Area_geom intersection [Km2]', 'Area_geom shape [Km2]', 'Percentage area',\n",
    "                                'Population intersection', 'Population shape', 'Percentage population'\n",
    "                                # 'Localities inside', 'Localities partially inside',\n",
    "                                ])\n",
    "    gjson_store.add_to(fg_merge_ind)\n",
    "\n",
    "    if i==0:\n",
    "        gdf_merge_concat = gdf_merge\n",
    "    else:\n",
    "        gdf_merge_concat = pd.concat([gdf_merge_concat, gdf_merge], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `fg_join` EXTERNAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(gdf_join) = 772\n",
      "shape(gdf_int_dd) =538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x204f9f61370>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdf_roi_4326.head(1)\n",
    "\n",
    "############# JOIN ####################\n",
    "gdf_join = gpd.sjoin(gdf_roi_4326, gdf_store_circles.to_crs(4326), how=\"inner\", predicate=\"intersects\")\n",
    "gdf_join['KFL_GPD'] = round(gdf_census_region.to_crs(6933).geometry.area / 10**6, round_dec)\n",
    "print(f'shape(gdf_join) = {gdf_join.shape[0]}')\n",
    "\n",
    "gdf_int_dd = gdf_join.drop_duplicates(subset=['OBJID'])\n",
    "gdf_int_dd['KFL_GPD'] = round(gdf_int_dd.to_crs(6933).geometry.area / 10**6, round_dec)\n",
    "print(f'shape(gdf_int_dd) ={gdf_int_dd.shape[0]}')\n",
    "### RELEVANT NUMBERS ###\n",
    "int_gem = gdf_int_dd.shape[0]\n",
    "int_ewz =gdf_join.EWZ.sum()\n",
    "int_area_roi_nomerge = gdf_join.KFL_GPD.sum()\n",
    "int_area_dbms_nomerge = gdf_join.KFL.sum()\n",
    "int_area_roi_merge   = gdf_int_dd.KFL_GPD.sum()\n",
    "int_area_dbms_merge   = gdf_int_dd.KFL.sum()\n",
    "\n",
    "### MESSAGE ###\n",
    "int_info_msg = f'# Towns={int_gem}, ' \\\n",
    "                f'# Area (geom, no merge)={int_area_roi_nomerge}Km2, ' \\\n",
    "                f'# Area (dbms, no merge)={int_area_dbms_nomerge}Km2, ' \\\n",
    "                f'Area (geom, merge)={int_area_roi_merge}Km2,' \\\n",
    "                f'Area (dbms, merge)={int_area_dbms_merge}Km2' \\\n",
    "                f'Pop={int_ewz}'\n",
    "\n",
    "### FEATURE GROUP ###\n",
    "fg_join = folium.FeatureGroup(name=f'Join/COMBINED [{int_info_msg}')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_join, \n",
    "                                  fields=['GEN', 'EWZ', 'KFL', 'KFL_GPD'],\n",
    "                                  aliases = ['Name', 'Population', 'Area_dbms', 'Area_Geom'])\n",
    "gjson_store.add_to(fg_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. GADMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group Countries (`fg_circ_merged_country`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 6)\n",
      "                                            geometry  ADMIN ISO_A3  \\\n",
      "0  POLYGON ((-69.99694 12.57758, -69.93639 12.531...  Aruba    ABW   \n",
      "\n",
      "   Area_total_km2  Area_land_km2  world_land_perc  \n",
      "0           180.0          180.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "gdf_world = f_maps.load_gdf_from_csv(path=paths.path_wca)\n",
    "print(gdf_world.shape)\n",
    "print(gdf_world.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_int_world = gpd.overlay(gdf_world.to_crs(6933), gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_int_world = gdf_int_world.drop_duplicates()\n",
    "gdf_int_world['area_intersection'] = round(gdf_int_world.geometry.area / 10**6, round_dec)\n",
    "# print(gdf_int_world.shape)\n",
    "# print(gdf_int_world.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `gdf_world`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_country_all` (gdf_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243b93695b0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering relevant countries\n",
    "gdf_world_contain = gdf_world[gdf_world['ISO_A3'].isin(gdf_int_world['ISO_A3'])]\n",
    "\n",
    "# gdf_world_contain\n",
    "fg_country_all = folium.FeatureGroup(name=f'Countries Intersecting [{gdf_world_contain.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_world_contain.to_crs(4326), \n",
    "                                  fields=['ADMIN', 'Area_total_km2'], \n",
    "                                  aliases=['name', 'Area [km2]'])\n",
    "gjson_store.add_to(fg_country_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_country_int` (gdf_world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243b6470aa0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_country_int = folium.FeatureGroup(name=f'ALL Country Join [{gdf_int_world.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_int_world.to_crs(4326), \n",
    "                                  fields=['ADMIN','area_intersection'], \n",
    "                                  aliases=['name', 'Area [km2]'])\n",
    "gjson_store.add_to(fg_country_int)\n",
    "\n",
    "# fg_join_country = folium.FeatureGroup(name=f'Country Join [{gdf_int_world.shape[0]}]')\n",
    "# for i,(index,country) in enumerate(gdf_int_world.iterrows()):\n",
    "#     print(f'[{i}/{gdf_int_world.shape[0]}] Country={country.ADMIN}')\n",
    "#     gpd_country = gpd.GeoDataFrame([country.to_dict()]).set_crs(6399).to_crs(4326)\n",
    "#     gjson = f_maps.get_folium_geojson(gpd_country, fields=['ADMIN'], aliases=['name'])\n",
    "#     gjson.add_to(fg_join_country)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GADM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_adm=assets/Geo/GADM/gadm41_AUT.gpkg\n"
     ]
    }
   ],
   "source": [
    "path = 'assets/Geo/GADM/gadm41_'\n",
    "country_3 = 'AUT'  # 3-letter country code\n",
    "l_adm = [\n",
    "    # 'ADM_ADM_0',    # COUNTRY\n",
    "    'ADM_ADM_1',    # STATE\n",
    "    # 'ADM_ADM_2',    # REGION\n",
    "    # 'ADM_ADM_3',    # COUNTY\n",
    "    # 'ADM_ADM_4',    # MUNICIPALITY\n",
    "    # 'ADM_ADM_5',  # SUB-MUNICIPALITY (Only France, Rwanda), aka PARISH\n",
    "    ]\n",
    "ext  = 'gpkg'\n",
    "path_adm = f'{path}{country_3}.{ext}'\n",
    "print(f'path_adm={path_adm}')  # PATH where the file is stored\n",
    "logging = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_world = f_maps.load_gdf_from_csv(path=paths.path_wca)\n",
    "gdf_int_world = gpd.overlay(gdf_world.to_crs(6933), gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_int_world = gdf_int_world.drop_duplicates()\n",
    "\n",
    "\n",
    "l_country_iso = list(gdf_int_world.ISO_A3.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_country_all` (GADM=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_adm = [\n",
    "    'ADM_ADM_0',    # COUNTRY\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Country=CHE\n",
      "path=assets/Geo/GADM/gadm41_CHE.gpkg\n",
      "ADM=0\n",
      "[2/3] Country=DEU\n",
      "path=assets/Geo/GADM/gadm41_DEU.gpkg\n",
      "ADM=0\n",
      "[3/3] Country=FRA\n",
      "path=assets/Geo/GADM/gadm41_FRA.gpkg\n",
      "ADM=0\n"
     ]
    }
   ],
   "source": [
    "for i,iso3 in enumerate(l_country_iso):\n",
    "    print(f'[{i+1}/{len(l_country_iso)}] Country={iso3}')\n",
    "    path_adm = f'{path}{iso3}.{ext}'\n",
    "    [l_gdf, l_name_adm, l_tooltip_adm ] = f_maps.extract_gdf_gpkg(\n",
    "        path       = path_adm, \n",
    "        l_levels   = l_adm,\n",
    "        is_logging = False\n",
    "    )\n",
    "    if i==0:\n",
    "        gdf_adm0 = l_gdf[0]\n",
    "    else:\n",
    "        gdf_adm0= pd.concat([gdf_adm0, l_gdf[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 7)\n",
      "  GID_0      COUNTRY  num_stores      area  perc_area  \\\n",
      "0   CHE  Switzerland          14  14119.32       0.39   \n",
      "\n",
      "                                            geometry  area_intersection  \n",
      "0  MULTIPOLYGON (((722255.399 5400604.903, 722938...             783.41  \n"
     ]
    }
   ],
   "source": [
    "gdf_int_countries = gpd.overlay(gdf_adm0.to_crs(6933), gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_int_countries = gdf_int_countries.drop_duplicates()\n",
    "gdf_int_countries['area_intersection'] = round(gdf_int_countries.geometry.area / 10**6, round_dec)\n",
    "print(gdf_int_countries.shape)\n",
    "print(gdf_int_countries.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Filtering relevant countries\n",
    "col_filter = 'COUNTRY'\n",
    "col_alias = 'Country'\n",
    "gdf_adm0_map = gdf_adm0[gdf_adm0[col_filter].isin(gdf_int_countries[col_filter])]\n",
    "print(gdf_adm0_map.shape)\n",
    "gdf_adm0_map = gdf_adm0_map.drop_duplicates()\n",
    "print(gdf_adm0_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243b93688f0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_gadm0_all = folium.FeatureGroup(name=f'Countries [{gdf_adm0_map.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_adm0_map,\n",
    "                                  fields=['COUNTRY', col_filter], \n",
    "                                  aliases=['Country', col_alias])\n",
    "gjson_store.add_to(fg_gadm0_all)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_country_int` (GADM=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_gadm0_int = gpd.overlay(gdf_adm0_map.to_crs(6933), gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_gadm0_int = gdf_gadm0_int.drop_duplicates()\n",
    "gdf_gadm0_int['area_intersection'] = round(gdf_gadm0_int.geometry.area / 10**6, round_dec)\n",
    "# print(gdf_gadm0_int.shape)\n",
    "# print(gdf_gadm0_int.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243cbcaf5f0>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_gadm0_ind = folium.FeatureGroup(name=f'ALL Countries Join [{gdf_gadm0_int.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_gadm0_int.to_crs(4326), \n",
    "                                  fields=['COUNTRY', 'area_intersection'], \n",
    "                                  aliases=['Country', 'Area[km2]'])\n",
    "gjson_store.add_to(fg_gadm0_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_states_all` (GADM=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_adm = [\n",
    "    'ADM_ADM_1',    # STATE\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] Country=CHE\n",
      "path=assets/Geo/GADM/gadm41_CHE.gpkg\n",
      "ADM=1\n",
      "yes\n",
      "l_columns=['COUNTRY', 'GID_0', 'NAME_1', 'TYPE_1']\n",
      "[2/3] Country=DEU\n",
      "path=assets/Geo/GADM/gadm41_DEU.gpkg\n",
      "ADM=1\n",
      "yes\n",
      "l_columns=['COUNTRY', 'GID_0', 'NAME_1', 'TYPE_1']\n",
      "[3/3] Country=FRA\n",
      "path=assets/Geo/GADM/gadm41_FRA.gpkg\n",
      "ADM=1\n",
      "yes\n",
      "l_columns=['COUNTRY', 'GID_0', 'NAME_1', 'TYPE_1']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i,iso3 in enumerate(l_country_iso):\n",
    "    print(f'[{i+1}/{len(l_country_iso)}] Country={iso3}')\n",
    "    path_adm = f'{path}{iso3}.{ext}'\n",
    "    [l_gdf, l_name_adm, l_tooltip_adm ] = f_maps.extract_gdf_gpkg(\n",
    "        path       = path_adm, \n",
    "        l_levels   = l_adm,\n",
    "        is_logging = False\n",
    "    )\n",
    "    if i==0:\n",
    "        gdf_adm1 = l_gdf[0]\n",
    "    else:\n",
    "        gdf_adm1 = pd.concat([gdf_adm1, l_gdf[0]])\n",
    "\n",
    "# print(gdf_adm1.shape)\n",
    "# print(gdf_adm1.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_int_states = gpd.overlay(gdf_adm1.to_crs(6933), gdf_store_circles_merged.to_crs(6933), how='intersection')\n",
    "gdf_int_states = gdf_int_states.drop_duplicates()\n",
    "gdf_int_states['area_intersection'] = round(gdf_int_states.geometry.area / 10**6, round_dec)\n",
    "# print(gdf_int_states.shape)\n",
    "# print(gdf_int_states.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 12)\n",
      "(12, 12)\n"
     ]
    }
   ],
   "source": [
    "# Filtering relevant countries\n",
    "col_filter = 'NAME_1'\n",
    "col_alias = 'State'\n",
    "gdf_adm1_map = gdf_adm1[gdf_adm1[col_filter].isin(gdf_int_states[col_filter])]\n",
    "print(gdf_adm1_map.shape)\n",
    "gdf_adm1_map = gdf_adm1_map.drop_duplicates()\n",
    "print(gdf_adm1_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243cad85730>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_states_all = folium.FeatureGroup(name=f'States [{gdf_adm1_map.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_adm1_map,\n",
    "                                  fields=['COUNTRY', col_filter], \n",
    "                                  aliases=['Country', col_alias])\n",
    "gjson_store.add_to(fg_states_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `fg_states_int` (GADM=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243cadc8bf0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg_states_int = folium.FeatureGroup(name=f'ALL States Join [{gdf_int_states.shape[0]}]')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_int_states.to_crs(4326), \n",
    "                                  fields=['COUNTRY', 'NAME_1', 'area_intersection'], \n",
    "                                  aliases=['Country', 'State', 'Area[km2]'])\n",
    "gjson_store.add_to(fg_states_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Group JOIN (`fg_join` using [`gdf_roi_4326` and `gdf_overlay`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape(gdf_join) = 772\n",
      "shape(gdf_int_dd) =538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<folium.features.GeoJson at 0x243b936a4e0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gdf_roi_4326.head(1)\n",
    "\n",
    "############# JOIN ####################\n",
    "gdf_join = gpd.sjoin(gdf_roi_4326, gdf_store_circles.to_crs(4326), how=\"inner\", predicate=\"intersects\")\n",
    "gdf_join['KFL_GPD'] = round(gdf_census_region.to_crs(6933).geometry.area / 10**6, round_dec)\n",
    "print(f'shape(gdf_join) = {gdf_join.shape[0]}')\n",
    "\n",
    "gdf_int_dd = gdf_join.drop_duplicates(subset=['OBJID'])\n",
    "gdf_int_dd['KFL_GPD'] = round(gdf_int_dd.to_crs(6933).geometry.area / 10**6, round_dec)\n",
    "print(f'shape(gdf_int_dd) ={gdf_int_dd.shape[0]}')\n",
    "### RELEVANT NUMBERS ###\n",
    "int_gem = gdf_int_dd.shape[0]\n",
    "int_ewz =gdf_join.EWZ.sum()\n",
    "int_area_roi_nomerge = gdf_join.KFL_GPD.sum()\n",
    "int_area_dbms_nomerge = gdf_join.KFL.sum()\n",
    "int_area_roi_merge   = gdf_int_dd.KFL_GPD.sum()\n",
    "int_area_dbms_merge   = gdf_int_dd.KFL.sum()\n",
    "\n",
    "### MESSAGE ###\n",
    "int_info_msg = f'# Towns={int_gem}, ' \\\n",
    "                f'# Area (geom, no merge)={int_area_roi_nomerge}Km2, ' \\\n",
    "                f'# Area (dbms, no merge)={int_area_dbms_nomerge}Km2, ' \\\n",
    "                f'Area (geom, merge)={int_area_roi_merge}Km2,' \\\n",
    "                f'Area (dbms, merge)={int_area_dbms_merge}Km2' \\\n",
    "                f'Pop={int_ewz}'\n",
    "\n",
    "### FEATURE GROUP ###\n",
    "fg_join = folium.FeatureGroup(name=f'Join/COMBINED [{int_info_msg}')\n",
    "gjson_store = f_maps.get_folium_geojson(gdf_join, \n",
    "                                  fields=['GEN', 'EWZ', 'KFL', 'KFL_GPD'],\n",
    "                                  aliases = ['Name', 'Population', 'Area_dbms', 'Area_Geom'])\n",
    "gjson_store.add_to(fg_join)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
